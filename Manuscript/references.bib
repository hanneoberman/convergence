@book{box15,
  title = {Time {{Series Analysis}}: {{Forecasting}} and {{Control}}},
  shorttitle = {Time {{Series Analysis}}},
  author = {Box, George E. P. and Jenkins, Gwilym M. and Reinsel, Gregory C. and Ljung, Greta M.},
  year = {2015},
  month = may,
  publisher = {John Wiley \& Sons},
  abstract = {Praise for the Fourth Edition  "The book follows faithfully the style of the original edition. The approach is heavily motivated by real-world time series, and by developing a complete approach to model building, estimation, forecasting and control."---Mathematical Reviews Bridging classical models and modern topics, the Fifth Edition of Time Series Analysis: Forecasting and Control maintains a balanced presentation of the tools for modeling and analyzing time series. Also describing the latest developments that have occurred in the field over the past decade through applications from areas such as business, finance, and engineering, the Fifth Edition continues to serve as one of the most influential and prominent works on the subject. Time Series Analysis: Forecasting and Control, Fifth Edition provides a clearly written exploration of the key methods for building, classifying, testing, and analyzing stochastic models for time series and describes their use in five important areas of application: forecasting; determining the transfer function of a system; modeling the effects of intervention events; developing multivariate dynamic models; and designing simple control schemes. Along with these classical uses, the new edition covers modern topics with new features that include:  A redesigned chapter on multivariate time series analysis with an expanded treatment of Vector Autoregressive, or VAR models, along with a discussion of the analytical tools needed for modeling vector time series An expanded chapter on special topics covering unit root testing, time-varying volatility models such as ARCH and GARCH, nonlinear time series models, and long memory models Numerous examples drawn from finance, economics, engineering, and other related fields The use of the publicly available R software for graphical illustrations and numerical calculations along with scripts that demonstrate the use of R for model building and forecasting Updates to literature references throughout and new end-of-chapter exercises Streamlined chapter introductions and revisions that update and enhance the exposition  Time Series Analysis: Forecasting and Control, Fifth Edition is a valuable real-world reference for researchers and practitioners in time series analysis, econometrics, finance, and related fields. The book is also an excellent textbook for beginning graduate-level courses in advanced statistics, mathematics, economics, finance, engineering, and physics.},
  googlebooks = {rNt5CgAAQBAJ},
  isbn = {978-1-118-67492-5},
  langid = {english},
  keywords = {Mathematics / Probability \& Statistics / General,Mathematics / Probability \& Statistics / Stochastic Processes}
}

@article{broo98,
  title = {General {{Methods}} for {{Monitoring Convergence}} of {{Iterative Simulations}}},
  author = {Brooks, Stephen P. and Gelman, Andrew},
  year = {1998},
  month = dec,
  journal = {Journal of Computational and Graphical Statistics},
  volume = {7},
  number = {4},
  pages = {434--455},
  doi = {10.1080/10618600.1998.10474787},
  urldate = {2019-09-20},
  abstract = {We generalize the method proposed by Gelman and Rubin (1992a) for monitoring the convergence of iterative simulations by comparing between and within variances of multiple chains, in order to obtain a family of tests for convergence. We review methods of inference from simulations in order to develop convergence-monitoring summaries that are relevant for the purposes for which the simulations are used. We recommend applying a battery of tests for mixing based on the comparison of inferences from individual sequences and from the mixture of sequences. Finally, we discuss multivariate analogues, for assessing convergence of several parameters simultaneously.},
  keywords = {Convergence diagnosis,Inference,Markov chain Monte Carlo},
  file = {C\:\\Users\\4216318\\Zotero\\storage\\Q7I49K25\\Brooks en Gelman - 1998 - General Methods for Monitoring Convergence of Iter.pdf;C\:\\Users\\4216318\\Zotero\\storage\\SDA8QD6T\\brooksgelman2.pdf;C\:\\Users\\4216318\\Zotero\\storage\\5Q2ITJG5\\10618600.1998.html}
}

@book{buur18,
  ids = {vanbuuren2018,vanbuuren2018a},
  title = {Flexible Imputation of Missing Data},
  author = {Van Buuren, Stef},
  year = {2018},
  publisher = {{Chapman and Hall/CRC}}
}

@article{cowl96,
  title = {Markov Chain {{Monte Carlo}} Convergence Diagnostics: A Comparative Review},
  author = {Cowles, Mary Kathryn and Carlin, Bradley P},
  year = {1996},
  journal = {Journal of the American Statistical Association},
  volume = {91},
  number = {434},
  pages = {883--904},
  file = {C:\Users\4216318\Zotero\storage\JIBHQIG4\CowlesCarlin.1996.pdf}
}

@incollection{drechslerDoesConvergenceReally2008,
  title = {Does {{Convergence Really Matter}}?},
  booktitle = {Recent {{Advances}} in {{Linear Models}} and {{Related Areas}}: {{Essays}} in {{Honour}} of {{Helge Toutenburg}}},
  author = {Drechsler, J{\"o}rg and R{\"a}ssler, Susanne},
  editor = {{Shalabh} and Heumann, Christian},
  year = {2008},
  pages = {341--355},
  publisher = {Physica-Verlag HD},
  address = {Heidelberg},
  doi = {10.1007/978-3-7908-2064-5_18},
  urldate = {2023-01-25},
  abstract = {For many data sets, especially for non mandatory surveys, missing data are a common problem. Deleting units that are not completely observed and using only the remaining units is a popular, easy to implement approach in this case. This can possibly introduce severe bias if the strong assumption of a missing pattern that is completely at random (MCAR) is not fulfilled (see for example Rubin (1987)). Imputing the missing values can overcome this problem. However, ad hoc methods like, e.g., mean imputation can destroy the correlation between the variables. Furthermore, imputing missing values only once (single imputation) generally doesn't account for the fact that the imputed values are only estimates for the true values. After the imputation process, they are treated like truly observed values leading to an underestimation of the variance in the data and by this to p values that are too significant.},
  isbn = {978-3-7908-2064-5},
  langid = {english},
  keywords = {Complete Case Analysis,Gibbs Sampler,Joint Distribution,Joint Modeling,Multiple Imputation},
  file = {C:\Users\4216318\Zotero\storage\8U6MQ5WT\Drechsler and Rässler - 2008 - Does Convergence Really Matter.pdf}
}

@article{elad06,
  title = {Comparison of Methodologies to Assess the Convergence of {{Markov}} Chain {{Monte Carlo}} Methods},
  author = {El Adlouni, Salaheddine and Favre, Anne-Catherine and Bob{\'e}e, Bernard},
  year = {2006},
  month = jun,
  journal = {Computational Statistics \& Data Analysis},
  volume = {50},
  number = {10},
  pages = {2685--2701},
  issn = {0167-9473},
  doi = {10.1016/j.csda.2005.04.018},
  urldate = {2019-09-20},
  abstract = {One major challenge with the modelization of complex problems using Markov chain Monte Carlo (MCMC) methods is the determination of the length of the chain in order to reach convergence. This paper is devoted to parametric empirical methods testing the stationarity. We compare the methods of Gelman and Rubin, Yu and Mykland, Raftery and Lewis, Geweke, Riemann sums and the subsampling. These methods are tested using three examples: the simple case of the generation of a normal random variable, a bivariate mixture of normal models and a practical case taken from hydrology, namely the shifting level model. Results show that no method works in every case. We therefore suggest a joint use of these techniques. The importance of determining carefully the burn-in period is also highlighted.},
  keywords = {Burn-in period,Convergence,Gelman and Rubin,Geweke,Gibbs sampler,MCMC,Raftery and Lewis,Riemann sums,Subsampling,Yu and Mykland},
  file = {C\:\\Users\\4216318\\Zotero\\storage\\BI6QI44D\\El Adlouni e.a. - 2006 - Comparison of methodologies to assess the converge.pdf;C\:\\Users\\4216318\\Zotero\\storage\\SF4UHRQ2\\S0167947305000836.html}
}

@book{gelm13,
  title = {Bayesian {{Data Analysis}}},
  author = {Gelman, Andrew and Carlin, John B. and Stern, Hal S. and Dunson, David B. and Vehtari, Aki and Rubin, Donald B.},
  year = {2013},
  publisher = {CRC Press LLC},
  address = {Philadelphia, PA, United States},
  urldate = {2019-09-12},
  keywords = {Bayesian statistical decision theory.},
  file = {C\:\\Users\\4216318\\Zotero\\storage\\ENZRIU2N\\Gelman e.a. - 2013 - Bayesian Data Analysis.pdf;C\:\\Users\\4216318\\Zotero\\storage\\ZSGD97ZP\\reader.html}
}

@article{gelm92,
  title = {Inference from {{Iterative Simulation Using Multiple Sequences}}},
  author = {Gelman, Andrew and Rubin, Donald B.},
  year = {1992},
  month = nov,
  journal = {Statistical Science},
  volume = {7},
  number = {4},
  pages = {457--472},
  doi = {10.1214/ss/1177011136},
  urldate = {2019-09-10},
  abstract = {The Gibbs sampler, the algorithm of Metropolis and similar iterative simulation methods are potentially very helpful for summarizing multivariate distributions. Used naively, however, iterative simulation can give misleading answers. Our methods are simple and generally applicable to the output of any iterative simulation; they are designed for researchers primarily interested in the science underlying the data and models they are analyzing, rather than for researchers interested in the probability theory underlying the iterative simulations themselves. Our recommended strategy is to use several independent sequences, with starting points sampled from an overdispersed distribution. At each step of the iterative simulation, we obtain, for each univariate estimand of interest, a distributional estimate and an estimate of how much sharper the distributional estimate might become if the simulations were continued indefinitely. Because our focus is on applied inference for Bayesian posterior distributions in real problems, which often tend toward normality after transformations and marginalization, we derive our results as normal-theory approximations to exact Bayesian inference, conditional on the observed simulations. The methods are illustrated on a random-effects mixture model applied to experimental measurements of reaction times of normal and schizophrenic patients.},
  langid = {english},
  zmnumber = {06853057},
  keywords = {Bayesian inference,convergence of stochastic processes,ECM,EM,Gibbs sampler,importance sampling,Metropolis algorithm,multiple imputation,random-effects model,SIR},
  file = {C\:\\Users\\4216318\\Zotero\\storage\\CWG9QXQK\\Gelman en Rubin - 1992 - Inference from Iterative Simulation Using Multiple.pdf;C\:\\Users\\4216318\\Zotero\\storage\\EK2UCSZT\\1177011136.html}
}

@book{hoff09,
  title = {A {{First Course}} in {{Bayesian Statistical Methods}}},
  author = {Hoff, Peter D.},
  year = {2009},
  series = {Springer {{Texts}} in {{Statistics}}},
  publisher = {Springer New York},
  address = {New York, NY},
  doi = {10.1007/978-0-387-92407-6},
  urldate = {2019-10-21},
  file = {C:\Users\4216318\Zotero\storage\YPEBD5NA\Hoff - 2009 - A First Course in Bayesian Statistical Methods.pdf}
}

@techreport{lace07,
  title = {Sequential Regression Multiple Imputation for Incomplete Multivariate Data Using {{Markov}} Chain {{Monte Carlo}}},
  author = {Lacerda, Miguel and Ardington, Cally and Leibbrandt, Murray},
  year = {2007},
  institution = {University of Cape Town, South Africa},
  file = {C:\Users\4216318\Zotero\storage\NIKK7HSY\2008_13.pdf}
}

@book{lync07,
  title = {Introduction to Applied {{Bayesian}} Statistics and Estimation for Social Scientists},
  author = {Lynch, Scott M.},
  year = {2007},
  publisher = {Springer Science \& Business Media},
  file = {C:\Users\4216318\Zotero\storage\GD5UTHAC\books.html}
}

@incollection{lynch2007,
  ids = {lynchEvaluatingMarkovChain2007a},
  title = {Evaluating {{Markov Chain Monte Carlo Algorithms}} and {{Model Fit}}},
  booktitle = {Introduction to {{Applied Bayesian Statistics}} and {{Estimation}} for {{Social Scientists}}},
  author = {Lynch, Scott M.},
  editor = {Lynch, Scott M.},
  year = {2007},
  pages = {131--164},
  publisher = {Springer New York},
  address = {New York, NY},
  doi = {10.1007/978-0-387-71265-9_6},
  urldate = {2022-06-17},
  isbn = {978-0-387-71264-2 978-0-387-71265-9},
  langid = {english},
  file = {C:\Users\4216318\Zotero\storage\M58Q5MM5\Lynch - 2007 - Evaluating Markov Chain Monte Carlo Algorithms and.pdf}
}

@book{mack03,
  title = {Information Theory, Inference and Learning Algorithms},
  author = {MacKay, David JC and Mac Kay, David JC},
  year = {2003},
  publisher = {Cambridge university press}
}

@article{mice,
  ids = {vanbuurenMiceMultivariateImputation2011},
  title = {Mice: {{Multivariate Imputation}} by {{Chained Equations}} in {{R}}},
  shorttitle = {Mice},
  author = {Van Buuren, Stef and {Groothuis-Oudshoorn}, Karin},
  year = {2011},
  month = dec,
  journal = {Journal of Statistical Software},
  volume = {45},
  number = {1},
  pages = {1--67},
  publisher = {American Statistical Association},
  doi = {10.18637/jss.v045.i03},
  urldate = {2019-09-05},
  copyright = {Copyright (c) 2009 Stef van Buuren, Karin Groothuis-Oudshoorn},
  date-added = {2016-02-04 23:31:15 +0000},
  date-modified = {2016-02-04 23:32:22 +0000},
  langid = {english},
  file = {C\:\\Users\\4216318\\Zotero\\storage\\W7DXJIVB\\Buuren en Groothuis-Oudshoorn - 2011 - mice Multivariate Imputation by Chained Equations.pdf;C\:\\Users\\4216318\\Zotero\\storage\\6GARXLG6\\v045i03.html}
}

@article{murray2018,
  title = {Multiple {{Imputation}}: {{A Review}} of {{Practical}} and {{Theoretical Findings}}},
  shorttitle = {Multiple {{Imputation}}},
  author = {Murray, Jared S.},
  year = {2018},
  month = may,
  journal = {Statistical Science},
  volume = {33},
  number = {2},
  pages = {142--159},
  publisher = {Institute of Mathematical Statistics},
  issn = {0883-4237, 2168-8745},
  doi = {10.1214/18-STS644},
  urldate = {2025-04-10},
  abstract = {Multiple imputation is a straightforward method for handling missing data in a principled fashion. This paper presents an overview of multiple imputation, including important theoretical results and their practical implications for generating and using multiple imputations. A review of strategies for generating imputations follows, including recent developments in flexible joint modeling and sequential regression/chained equations/fully conditional specification approaches. Finally, we compare and contrast different methods for generating imputations on a range of criteria before identifying promising avenues for future research.},
  keywords = {chained equations,Congeniality,fully conditional specification,missing data,proper imputation,sequential regression multivariate imputation},
  file = {C:\Users\4216318\Zotero\storage\PLYUKWTM\Murray - 2018 - Multiple Imputation A Review of Practical and The.pdf}
}

@book{mvtnorm,
  title = {Computation of Multivariate Normal and t Probabilities},
  author = {Genz, Alan and Bretz, Frank},
  year = {2009},
  series = {Lecture Notes in Statistics},
  publisher = {Springer-Verlag},
  address = {Heidelberg},
  isbn = {978-3-642-01688-2}
}

@book{R,
  ids = {rcoreteamLanguageEnvironmentStatistical2020},
  title = {R: {{A}} Language and Environment for Statistical Computing},
  author = {{R Core Team}},
  year = {2020},
  address = {Vienna, Austria},
  organization = {R Foundation for Statistical Computing}
}

@techreport{ragh07,
  type = {{{SSRN Scholarly Paper}}},
  title = {Diagnostics for {{Multiple Imputations}}},
  author = {Raghunathan, Trivellore and Bondarenko, Irina},
  year = {2007},
  month = nov,
  number = {ID 1031750},
  address = {Rochester, NY},
  institution = {Social Science Research Network},
  urldate = {2019-10-17},
  abstract = {Multiple imputation technique is becoming a popular method for analyzing data with missing values. Several methods have been proposed for creating multiple imputations and most of these methods assume that the data are missing at random (MAR). However, limited diagnostic tools are available to check whether the imputations created by these methods are reasonable. This article develops a set of diagnostic tools based on certain conditional distributions of the observed and imputed values. These conditional distributions should be similar if the assumed model for creating multiple imputations is a good fit. The tools are formulated in terms of numerical summaries and graphical displays and could be easily implemented using the standard complete data software packages. For implementing these methods the exact nature of the model used by the imputer is not needed. The method is illustrated using a data set with large number of variables of different types with varying amount of missing values.},
  langid = {english},
  keywords = {Congeniality,Diagnostics,Missing at Random,Propensity score matching},
  file = {C:\Users\4216318\Zotero\storage\WL7ZL76E\Raghunathan en Bondarenko - 2007 - Diagnostics for Multiple Imputations.pdf}
}

@misc{RankNormalizationFoldingLocalization,
  title = {Rank-{{Normalization}}, {{Folding}}, and {{Localization}}: {{An Improved R{\textasciicircum}}} for {{Assessing Convergence}} of {{MCMC}} (with {{Discussion}})},
  urldate = {2022-10-13},
  howpublished = {https://projecteuclid-org.proxy.library.uu.nl/journals/bayesian-analysis/volume-16/issue-2/Rank-Normalization-Folding-and-Localization--An-Improved-R\%cb\%86-for/10.1214/20-BA1221.full},
  file = {C:\Users\4216318\Zotero\storage\KYKA2XC4\20-BA1221.html}
}

@misc{RankNormalizationFoldingLocalization,
  title = {Rank-{{Normalization}}, {{Folding}}, and {{Localization}}: {{An Improved R}}{\textasciicircum} for {{Assessing Convergence}} of {{MCMC}} (with {{Discussion}})},
  file = {C:\Users\4216318\Zotero\storage\NYGESIZI\20-BA1221.html}
}

@misc{royConvergenceDiagnosticsMarkov2019,
  title = {Convergence Diagnostics for {{Markov}} Chain {{Monte Carlo}}},
  author = {Roy, Vivekananda},
  year = {2019},
  month = oct,
  number = {arXiv:1909.11827},
  eprint = {1909.11827},
  primaryclass = {stat},
  publisher = {arXiv},
  urldate = {2022-06-17},
  abstract = {Markov chain Monte Carlo (MCMC) is one of the most useful approaches to scientific computing because of its flexible construction, ease of use and generality. Indeed, MCMC is indispensable for performing Bayesian analysis. Two critical questions that MCMC practitioners need to address are where to start and when to stop the simulation. Although a great amount of research has gone into establishing convergence criteria and stopping rules with sound theoretical foundation, in practice, MCMC users often decide convergence by applying empirical diagnostic tools. This review article discusses the most widely used MCMC convergence diagnostic tools. Some recently proposed stopping rules with firm theoretical footing are also presented. The convergence diagnostics and stopping rules are illustrated using three detailed examples.},
  archiveprefix = {arXiv},
  keywords = {{60J05, 62F15, 65C40},Statistics - Computation},
  file = {C\:\\Users\\4216318\\Zotero\\storage\\NGBNKPGJ\\Roy - 2019 - Convergence diagnostics for Markov chain Monte Car.pdf;C\:\\Users\\4216318\\Zotero\\storage\\86TBEANZ\\1909.html}
}

@misc{royConvergenceDiagnosticsMarkov2019,
  title = {Convergence Diagnostics for {{Markov}} Chain {{Monte Carlo}}},
  author = {Roy, Vivekananda},
  year = {2019},
  month = oct,
  number = {arXiv:1909.11827},
  eprint = {1909.11827},
  primaryclass = {stat},
  publisher = {arXiv},
  abstract = {Markov chain Monte Carlo (MCMC) is one of the most useful approaches to scientific computing because of its flexible construction, ease of use and generality. Indeed, MCMC is indispensable for performing Bayesian analysis. Two critical questions that MCMC practitioners need to address are where to start and when to stop the simulation. Although a great amount of research has gone into establishing convergence criteria and stopping rules with sound theoretical foundation, in practice, MCMC users often decide convergence by applying empirical diagnostic tools. This review article discusses the most widely used MCMC convergence diagnostic tools. Some recently proposed stopping rules with firm theoretical footing are also presented. The convergence diagnostics and stopping rules are illustrated using three detailed examples.},
  archiveprefix = {arXiv},
  keywords = {60J05,62F15,65C40,Statistics - Computation},
  file = {C\:\\Users\\4216318\\Zotero\\storage\\643IZTZM\\Roy - 2019 - Convergence diagnostics for Markov chain Monte Car.pdf;C\:\\Users\\4216318\\Zotero\\storage\\SUPCPDFM\\1909.html}
}

@misc{royConvergenceDiagnosticsMarkov2019a,
  title = {Convergence Diagnostics for {{Markov}} Chain {{Monte Carlo}}},
  author = {Roy, Vivekananda},
  year = {2019},
  month = oct,
  number = {arXiv:1909.11827},
  eprint = {1909.11827},
  primaryclass = {stat},
  publisher = {arXiv},
  urldate = {2022-07-14},
  abstract = {Markov chain Monte Carlo (MCMC) is one of the most useful approaches to scientific computing because of its flexible construction, ease of use and generality. Indeed, MCMC is indispensable for performing Bayesian analysis. Two critical questions that MCMC practitioners need to address are where to start and when to stop the simulation. Although a great amount of research has gone into establishing convergence criteria and stopping rules with sound theoretical foundation, in practice, MCMC users often decide convergence by applying empirical diagnostic tools. This review article discusses the most widely used MCMC convergence diagnostic tools. Some recently proposed stopping rules with firm theoretical footing are also presented. The convergence diagnostics and stopping rules are illustrated using three detailed examples.},
  archiveprefix = {arXiv},
  keywords = {{60J05, 62F15, 65C40},Statistics - Computation},
  file = {C\:\\Users\\4216318\\Zotero\\storage\\2JSSQ64U\\Roy - 2019 - Convergence diagnostics for Markov chain Monte Car.pdf;C\:\\Users\\4216318\\Zotero\\storage\\BRN3LZVR\\1909.html}
}

@misc{royConvergenceDiagnosticsMarkov2019a,
  title = {Convergence Diagnostics for {{Markov}} Chain {{Monte Carlo}}},
  author = {Roy, Vivekananda},
  year = {2019},
  month = oct,
  number = {arXiv:1909.11827},
  eprint = {1909.11827},
  primaryclass = {stat},
  publisher = {arXiv},
  abstract = {Markov chain Monte Carlo (MCMC) is one of the most useful approaches to scientific computing because of its flexible construction, ease of use and generality. Indeed, MCMC is indispensable for performing Bayesian analysis. Two critical questions that MCMC practitioners need to address are where to start and when to stop the simulation. Although a great amount of research has gone into establishing convergence criteria and stopping rules with sound theoretical foundation, in practice, MCMC users often decide convergence by applying empirical diagnostic tools. This review article discusses the most widely used MCMC convergence diagnostic tools. Some recently proposed stopping rules with firm theoretical footing are also presented. The convergence diagnostics and stopping rules are illustrated using three detailed examples.},
  archiveprefix = {arXiv},
  keywords = {60J05,62F15,65C40,Statistics - Computation},
  file = {C\:\\Users\\4216318\\Zotero\\storage\\BZJVVYI6\\Roy - 2019 - Convergence diagnostics for Markov chain Monte Car.pdf;C\:\\Users\\4216318\\Zotero\\storage\\48FW9PSH\\1909.html}
}

@article{rubin76,
  ids = {rubin1976,rubin1976a,rubin1976inference},
  title = {Inference and {{Missing Data}}},
  author = {Rubin, Donald B.},
  year = {1976},
  journal = {Biometrika},
  volume = {63},
  number = {3},
  pages = {581--592},
  publisher = {Biometrika Trust},
  doi = {10.2307/2335739},
  urldate = {2020-04-03},
  abstract = {When making sampling distribution inferences about the parameter of the data, {\texttheta}, it is appropriate to ignore the process that causes missing data if the missing data are `missing at random' and the observed data are `observed at random', but these inferences are generally conditional on the observed pattern of missing data. When making direct-likelihood or Bayesian inferences about {\texttheta}, it is appropriate to ignore the process that causes missing data if the missing data are missing at random and the parameter of the missing data process is `distinct' from {\texttheta}. These conditions are the weakest general conditions under which ignoring the process that causes missing data always leads to correct inferences.},
  date-added = {2016-01-31 19:05:50 +0000},
  date-modified = {2016-01-31 19:05:50 +0000},
  file = {C:\Users\4216318\Zotero\storage\XIZEI53J\Rubin - 1976 - Inference and Missing Data.pdf}
}

@book{rubin87,
  ids = {rubin1987},
  title = {Multiple {{Imputation}} for Nonresponse in Surveys},
  author = {Rubin, Donald B.},
  year = {1987},
  series = {Wiley Series in Probability and Mathematical Statistics {{Applied}} Probability and Statistics},
  publisher = {Wiley},
  address = {New York, NY},
  date-added = {2016-01-31 18:37:31 +0000},
  date-modified = {2016-01-31 18:41:54 +0000},
  langid = {english},
  file = {C:\Users\4216318\Zotero\storage\63UKR3PY\Rubin - 1987 - Multiple Imputation for nonresponse in surveys.pdf}
}

@article{rubin96,
  title = {Multiple {{Imputation After}} 18+ {{Years}}},
  author = {Rubin, Donald B.},
  year = {1996},
  journal = {Journal of the American Statistical Association},
  volume = {91},
  number = {434},
  pages = {473--489},
  doi = {10.2307/2291635},
  abstract = {[Multiple imputation was designed to handle the problem of missing data in public-use data bases where the data-base constructor and the ultimate user are distinct entities. The objective is valid frequency inference for ultimate users who in general have access only to complete-data software and possess limited knowledge of specific reasons and models for nonresponse. For this situation and objective, I believe that multiple imputation by the data-base constructor is the method of choice. This article first provides a description of the assumed context and objectives, and second, reviews the multiple imputation framework and its standard results. These preliminary discussions are especially important because some recent commentaries on multiple imputation have reflected either misunderstandings of the practical objectives of multiple imputation or misunderstandings of fundamental theoretical results. Then, criticisms of multiple imputation are considered, and, finally, comparisons are made to alternative strategies.]},
  file = {C:\Users\4216318\Zotero\storage\9UVT28MF\Rubin - Multiple Imputation after 18+ years.pdf}
}

@book{scha97,
  title = {Analysis of Incomplete Multivariate Data},
  author = {Schafer, Joseph L},
  year = {1997},
  publisher = {{Chapman and Hall/CRC}},
  file = {C\:\\Users\\4216318\\Zotero\\storage\\Q7G6U2VV\\Schafer - 1997 - Analysis of incomplete multivariate data.pdf;C\:\\Users\\4216318\\Zotero\\storage\\VEI29NIR\\Schafer - 1997 - Analysis of incomplete multivariate data.pdf}
}

@book{shalabhRecentAdvancesLinear2008,
  title = {Recent Advances in Linear Models and Related Areas: Essays in Honour of {{Helge Toutenburg}}},
  shorttitle = {Recent Advances in Linear Models and Related Areas},
  editor = {Shalabh and Heumann, Christian and Toutenburg, Helge},
  year = {2008},
  publisher = {Physica ; Springer [distributor]},
  address = {Heidelberg : London},
  isbn = {978-3-7908-2063-8},
  langid = {english},
  lccn = {QA278.2 .R42 2008},
  keywords = {Aufsatzsammlung,Linear models (Statistics),Lineares Modell,Regression analysis,Regressionsanalyse},
  annotation = {OCLC: ocn228583260},
  file = {C:\Users\4216318\Zotero\storage\DXKJGCRE\978-3-7908-2064-5.pdf}
}

@article{takahashi2017,
  ids = {taka17},
  title = {Statistical {{Inference}} in {{Missing Data}} by {{MCMC}} and {{Non-MCMC Multiple Imputation Algorithms}}: {{Assessing}} the {{Effects}} of {{Between-Imputation Iterations}}},
  shorttitle = {Statistical {{Inference}} in {{Missing Data}} by {{MCMC}} and {{Non-MCMC Multiple Imputation Algorithms}}},
  author = {Takahashi, Masayoshi},
  year = {2017},
  month = jul,
  journal = {Data Science Journal},
  volume = {16},
  number = {0},
  pages = {37},
  publisher = {Ubiquity Press},
  issn = {1683-1470},
  doi = {10.5334/dsj-2017-037},
  urldate = {2021-08-12},
  abstract = {Incomplete data are ubiquitous in social sciences; as a consequence, available data are inefficient (ineffective) and often biased. In the literature, multiple imputation is known to be the standard method to handle missing data. While the theory of multiple imputation has been known for decades, the implementation is difficult due to the complicated nature of random draws from the posterior distribution. Thus, there are several computational algorithms in software: Data Augmentation (DA), Fully Conditional Specification (FCS), and Expectation-Maximization with Bootstrapping (EMB). Although the literature is full of comparisons between joint modeling (DA, EMB) and conditional modeling (FCS), little is known about the relative superiority between the MCMC algorithms (DA, FCS) and the non-MCMC algorithm (EMB), where MCMC stands for Markov chain Monte Carlo. Based on simulation experiments, the current study contends that EMB is a confidence proper (confidence-supporting) multiple imputation algorithm without between-imputation iterations; thus, EMB is more user-friendly than DA and FCS.},
  copyright = {Authors who publish with this journal agree to the following terms:    Authors retain copyright and grant the journal right of first publication with the work simultaneously licensed under a  Creative Commons Attribution License  that allows others to share the work with an acknowledgement of the work's authorship and initial publication in this journal.  Authors are able to enter into separate, additional contractual arrangements for the non-exclusive distribution of the journal's published version of the work (e.g., post it to an institutional repository or publish it in a book), with an acknowledgement of its initial publication in this journal.  Authors are permitted and encouraged to post their work online (e.g., in institutional repositories or on their website) prior to and during the submission process, as it can lead to productive exchanges, as well as earlier and greater citation of published work (See  The Effect of Open Access ).  All third-party images reproduced on this journal are shared under Educational Fair Use. For more information on  Educational Fair Use , please see  this useful checklist prepared by Columbia University Libraries .   All copyright  of third-party content posted here for research purposes belongs to its original owners.  Unless otherwise stated all references to characters and comic art presented on this journal are {\copyright}, {\textregistered} or ™ of their respective owners. No challenge to any owner's rights is intended or should be inferred.},
  langid = {english},
  keywords = {Conditional modeling,Incomplete data,Joint modeling,Markov chain Monte Carlo,MCMC,Nonresponse},
  file = {C\:\\Users\\4216318\\Zotero\\storage\\SUSARTC8\\Takahashi - 2017 - Statistical Inference in Missing Data by MCMC and .pdf;C\:\\Users\\4216318\\Zotero\\storage\\UC3SL5U6\\Takahashi - 2017 - Statistical Inference in Missing Data by MCMC and .pdf;C\:\\Users\\4216318\\Zotero\\storage\\7CQK44S2\\dsj-2017-037.html;C\:\\Users\\4216318\\Zotero\\storage\\UJTMEUVT\\dsj-2017-037.html}
}

@article{vehtari2021,
  title = {Rank-{{Normalization}}, {{Folding}}, and {{Localization}}: {{An Improved R{\textasciicircum}}} for {{Assessing Convergence}} of {{MCMC}}},
  shorttitle = {Rank-{{Normalization}}, {{Folding}}, and {{Localization}}},
  author = {Vehtari, Aki and Gelman, Andrew and Simpson, Daniel and Carpenter, Bob and B{\"u}rkner, Paul-Christian},
  year = {2021},
  month = jan,
  journal = {Bayesian Analysis},
  volume = {-1},
  number = {-1},
  pages = {1--38},
  publisher = {International Society for Bayesian Analysis},
  issn = {1936-0975, 1931-6690},
  doi = {10.1214/20-BA1221},
  urldate = {2021-06-21},
  abstract = {Markov chain Monte Carlo is a key computational tool in Bayesian statistics, but it can be challenging to monitor the convergence of an iterative stochastic algorithm. In this paper we show that the convergence diagnostic R{\textasciicircum} of Gelman and Rubin (1992) has serious flaws. Traditional R{\textasciicircum} will fail to correctly diagnose convergence failures when the chain has a heavy tail or when the variance varies across the chains. In this paper we propose an alternative rank-based diagnostic that fixes these problems. We also introduce a collection of quantile-based local efficiency measures, along with a practical approach for computing Monte Carlo error estimates for quantiles. We suggest that common trace plots should be replaced with rank plots from multiple chains. Finally, we give recommendations for how these methods should be used in practice.},
  file = {C\:\\Users\\4216318\\Zotero\\storage\\ZMWY33IX\\Vehtari et al. - 2021 - Rank-Normalization, Folding, and Localization An .pdf;C\:\\Users\\4216318\\Zotero\\storage\\526QZS5S\\20-BA1221.html;C\:\\Users\\4216318\\Zotero\\storage\\GC97HRL7\\20-BA1221.html}
}

@article{zhu15,
  title = {Convergence {{Properties}} of a {{Sequential Regression Multiple Imputation Algorithm}}},
  author = {Zhu, Jian and Raghunathan, Trivellore E.},
  year = {2015},
  month = jul,
  journal = {Journal of the American Statistical Association},
  volume = {110},
  number = {511},
  pages = {1112--1124},
  doi = {10.1080/01621459.2014.948117},
  urldate = {2019-09-10},
  abstract = {A sequential regression or chained equations imputation approach uses a Gibbs sampling-type iterative algorithm that imputes the missing values using a sequence of conditional regression models. It is a flexible approach for handling different types of variables and complex data structures. Many simulation studies have shown that the multiple imputation inferences based on this procedure have desirable repeated sampling properties. However, a theoretical weakness of this approach is that the specification of a set of conditional regression models may not be compatible with a joint distribution of the variables being imputed. Hence, the convergence properties of the iterative algorithm are not well understood. This article develops conditions for convergence and assesses the properties of inferences from both compatible and incompatible sequence of regression models. The results are established for the missing data pattern where each subject may be missing a value on at most one variable. The sequence of regression models are assumed to be empirically good fit for the data chosen by the imputer based on appropriate model diagnostics. The results are used to develop criteria for the choice of regression models. Supplementary materials for this article are available online.},
  keywords = {Bayesian analysis,Chained equations,Compatible conditionals,Conditional specifications,Exponential family,Gibbs sampling,Missing data.},
  file = {C\:\\Users\\4216318\\Zotero\\storage\\FPPUB4TU\\Zhu en Raghunathan - 2015 - Convergence Properties of a Sequential Regression .pdf;C\:\\Users\\4216318\\Zotero\\storage\\CJWQJ3FF\\01621459.2014.html}
}

@misc{zotero-13423,
  title = {He: {{Multiple}} Imputation in a Large-Scale Complex... - {{Google Scholar}}},
  urldate = {2024-02-20},
  howpublished = {https://scholar.google.com/scholar\_lookup?journal=Statistical+Methods+in+Medical+Research\&title=Multiple+imputation+in+a+large\%E2\%80\%90scale+complex+survey\%3A+a+practical+guide\&publication\_year=2009\&pages=1-18\&doi=10.1177\%2F0962280208101273\&inst=7240083048524121927}
}
