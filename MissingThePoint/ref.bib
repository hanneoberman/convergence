
@article{abay08,
  title = {Diagnostics for Multivariate Imputations},
  author = {Abayomi, Kobi and Gelman, Andrew and Levy, Marc},
  date = {2008-06},
  journaltitle = {Journal of the Royal Statistical Society: Series C (Applied Statistics)},
  shortjournal = {J Royal Statistical Soc C},
  volume = {57},
  number = {3},
  pages = {273--291},
  issn = {0035-9254, 1467-9876},
  doi = {10.1111/j.1467-9876.2007.00613.x},
  url = {http://doi.wiley.com/10.1111/j.1467-9876.2007.00613.x},
  urldate = {2019-09-03},
  abstract = {We consider three sorts of diagnostics for random imputations: displays of the completed data, which are intended to reveal unusual patterns that might suggest problems with the imputations, comparisons of the distributions of observed and imputed data values and checks of the fit of observed data to the model that is used to create the imputations. We formulate these methods in terms of sequential regression multivariate imputation, which is an iterative procedure in which the missing values of each variable are randomly imputed conditionally on all the other variables in the completed data matrix. We also consider a recalibration procedure for sequential regression imputations. We apply these methods to the 2002 environmental sustainability index, which is a linear aggregation of 64 environmental variables on 142 countries.},
  langid = {english},
  file = {C\:\\Users\\4216318\\Zotero\\storage\\YHCKE6CH\\Abayomi e.a. - 2008 - Diagnostics for multivariate imputations.pdf}
}

@book{alli02,
  title = {Missing Data},
  author = {Allison, Paul D.},
  date = {2001},
  publisher = {{Sage publications}},
  file = {C\:\\Users\\4216318\\Zotero\\storage\\KHTDX984\\books.html}
}

@article{allisonMultipleImputationMissing2000,
  title = {Multiple {{Imputation}} for {{Missing Data}}: A {{Cautionary Tale}}},
  shorttitle = {Multiple {{Imputation}} for {{Missing Data}}},
  author = {ALLISON, PAUL D.},
  date = {2000-02-01},
  journaltitle = {Sociological Methods \& Research},
  shortjournal = {Sociological Methods \& Research},
  volume = {28},
  number = {3},
  pages = {301--309},
  publisher = {{SAGE Publications Inc}},
  issn = {0049-1241},
  doi = {10.1177/0049124100028003003},
  url = {https://doi.org/10.1177/0049124100028003003},
  urldate = {2020-03-04},
  abstract = {Two algorithms for producing multiple imputations for missing data are evaluated with simulated data. Software using a propensity score classifier with the approximate Bayesian bootstrap produces badly biased estimates of regression coefficients when data on predictor variables are missing at random or missing completely at random. On the other hand, a regression-based method employing the data augmentation algorithm produces estimates with little or no bias.},
  file = {C\:\\Users\\4216318\\Zotero\\storage\\J6TQ4ITP\\ALLISON - 2000 - Multiple Imputation for Missing Data A Cautionary.pdf}
}

@inproceedings{andreassonEffectsVisualizingMissing2014,
  title = {Effects of {{Visualizing Missing Data}}: An {{Empirical Evaluation}}},
  shorttitle = {Effects of {{Visualizing Missing Data}}},
  booktitle = {2014 18th {{International Conference}} on {{Information Visualisation}}},
  author = {Andreasson, Rebecca and Riveiro, Maria},
  date = {2014-07},
  pages = {132--138},
  issn = {2375-0138},
  doi = {10.1109/IV.2014.77},
  abstract = {This paper presents an empirical study that evaluates the effects of visualizing missing data on decision-making tasks. A comparison between three visualization techniques: (1) emptiness, (2) fuzziness, and (3) emptiness plus explanation, revealed that the latter technique induced significantly higher degree of decision-confidence than the visualization technique fuzziness. Moreover, emptiness plus explanation yield the highest number of risky choices of the three. This result suggests that uncertainty visualization techniques affect the decision-maker and the decisionconfidence. Additionally, the results indicate a possible relation between the degree of decision-confidence and the decision-maker's displayed risk behavior.},
  eventtitle = {2014 18th {{International Conference}} on {{Information Visualisation}}},
  keywords = {Data visualization,Decision making,decision-making,Educational institutions,Image color analysis,meta-information,missing data,Reliability,Uncertainty,visual analytics,visualization,Visualization},
  file = {C\:\\Users\\4216318\\Zotero\\storage\\58VI7LNW\\6902893.html}
}

@inproceedings{andreassonEffectsVisualizingMissing2014a,
  title = {Effects of {{Visualizing Missing Data}}: An {{Empirical Evaluation}}},
  shorttitle = {Effects of {{Visualizing Missing Data}}},
  booktitle = {2014 18th {{International Conference}} on {{Information Visualisation}}},
  author = {Andreasson, Rebecca and Riveiro, Maria},
  date = {2014-07},
  pages = {132--138},
  issn = {2375-0138},
  doi = {10.1109/IV.2014.77},
  abstract = {This paper presents an empirical study that evaluates the effects of visualizing missing data on decision-making tasks. A comparison between three visualization techniques: (1) emptiness, (2) fuzziness, and (3) emptiness plus explanation, revealed that the latter technique induced significantly higher degree of decision-confidence than the visualization technique fuzziness. Moreover, emptiness plus explanation yield the highest number of risky choices of the three. This result suggests that uncertainty visualization techniques affect the decision-maker and the decisionconfidence. Additionally, the results indicate a possible relation between the degree of decision-confidence and the decision-maker's displayed risk behavior.},
  eventtitle = {2014 18th {{International Conference}} on {{Information Visualisation}}},
  keywords = {Data visualization,Decision making,decision-making,Educational institutions,Image color analysis,meta-information,missing data,Reliability,Uncertainty,visual analytics,visualization,Visualization},
  file = {C\:\\Users\\4216318\\Zotero\\storage\\MU798VLD\\6902893.html}
}

@article{bang05,
  title = {Doubly {{Robust Estimation}} in {{Missing Data}} and {{Causal Inference Models}}},
  author = {Bang, Heejung and Robins, James M.},
  date = {2005},
  journaltitle = {Biometrics},
  volume = {61},
  number = {4},
  pages = {962--973},
  issn = {1541-0420},
  doi = {10.1111/j.1541-0420.2005.00377.x},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/j.1541-0420.2005.00377.x},
  urldate = {2019-10-02},
  abstract = {The goal of this article is to construct doubly robust (DR) estimators in ignorable missing data and causal inference models. In a missing data model, an estimator is DR if it remains consistent when either (but not necessarily both) a model for the missingness mechanism or a model for the distribution of the complete data is correctly specified. Because with observational data one can never be sure that either a missingness model or a complete data model is correct, perhaps the best that can be hoped for is to find a DR estimator. DR estimators, in contrast to standard likelihood-based or (nonaugmented) inverse probability-weighted estimators, give the analyst two chances, instead of only one, to make a valid inference. In a causal inference model, an estimator is DR if it remains consistent when either a model for the treatment assignment mechanism or a model for the distribution of the counterfactual data is correctly specified. Because with observational data one can never be sure that a model for the treatment assignment mechanism or a model for the counterfactual data is correct, inference based on DR estimators should improve upon previous approaches. Indeed, we present the results of simulation studies which demonstrate that the finite sample performance of DR estimators is as impressive as theory would predict. The proposed method is applied to a cardiovascular clinical trial.},
  langid = {english},
  keywords = {Causal inference,Doubly robust estimation,Longitudinal data,Marginal structural model,Missing data,Semiparametrics},
  file = {C\:\\Users\\4216318\\Zotero\\storage\\KJSVWNQL\\Bang en Robins - 2005 - Doubly Robust Estimation in Missing Data and Causa.pdf;C\:\\Users\\4216318\\Zotero\\storage\\MVAKGY8K\\j.1541-0420.2005.00377.html}
}

@article{bart15,
  ids = {bartlettMultipleImputationCovariates2015},
  title = {Multiple Imputation of Covariates by Fully Conditional Specification: Accommodating the Substantive Model},
  shorttitle = {Multiple Imputation of Covariates by Fully Conditional Specification},
  author = {Bartlett, Jonathan W and Seaman, Shaun R and White, Ian R and Carpenter, James R},
  date = {2015-08-01},
  journaltitle = {Statistical Methods in Medical Research},
  shortjournal = {Stat Methods Med Res},
  volume = {24},
  number = {4},
  eprint = {24525487},
  eprinttype = {pmid},
  pages = {462--487},
  issn = {0962-2802},
  doi = {10.1177/0962280214521348},
  url = {https://doi.org/10.1177/0962280214521348},
  urldate = {2019-09-03},
  abstract = {Missing covariate data commonly occur in epidemiological and clinical research, and are often dealt with using multiple imputation. Imputation of partially observed covariates is complicated if the substantive model is non-linear (e.g. Cox proportional hazards model), or contains non-linear (e.g. squared) or interaction terms, and standard software implementations of multiple imputation may impute covariates from models that are incompatible with such substantive models. We show how imputation by fully conditional specification, a popular approach for performing multiple imputation, can be modified so that covariates are imputed from models which are compatible with the substantive model. We investigate through simulation the performance of this proposal, and compare it with existing approaches. Simulation results suggest our proposal gives consistent estimates for a range of common substantive models, including models which contain non-linear covariate effects or interactions, provided data are missing at random and the assumed imputation models are correctly specified and mutually compatible. Stata software implementing the approach is freely available.},
  langid = {english},
  pmcid = {PMC4513015},
  keywords = {*Models; Statistical,compatibility,fully conditional specification,interactions,multiple imputation,non-linearities,rejection sampling},
  file = {C\:\\Users\\4216318\\Zotero\\storage\\IP6F7U98\\Bartlett e.a. - 2015 - Multiple imputation of covariates by fully conditi.pdf}
}

@article{bond16,
  title = {Graphical and Numerical Diagnostic Tools to Assess Suitability of Multiple Imputations and Imputation Models},
  author = {Bondarenko, Irina and Raghunathan, Trivellore},
  date = {2016},
  journaltitle = {Statistics in Medicine},
  volume = {35},
  number = {17},
  pages = {3007--3020},
  issn = {1097-0258},
  doi = {10.1002/sim.6926},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/sim.6926},
  urldate = {2019-09-27},
  abstract = {Multiple imputation has become a popular approach for analyzing incomplete data. Many software packages are available to multiply impute the missing values and to analyze the resulting completed data sets. However, diagnostic tools to check the validity of the imputations are limited, and the majority of the currently available methods need considerable knowledge of the imputation model. In many practical settings, however, the imputer and the analyst may be different individuals or from different organizations, and the analyst model may or may not be congenial to the model used by the imputer. This article develops and evaluates a set of graphical and numerical diagnostic tools for two practical purposes: (i) for an analyst to determine whether the imputations are reasonable under his/her model assumptions without actually knowing the imputation model assumptions; and (ii) for an imputer to fine tune the imputation model by checking the key characteristics of the observed and imputed values. The tools are based on the numerical and graphical comparisons of the distributions of the observed and imputed values conditional on the propensity of response. The methodology is illustrated using simulated data sets created under a variety of scenarios. The examples focus on continuous and binary variables, but the principles can be used to extend methods for other types of variables. Copyright © 2016 John Wiley \& Sons, Ltd.},
  langid = {english},
  keywords = {congeniality,diagnostics,multiple imputation,propensity score},
  file = {C\:\\Users\\4216318\\Zotero\\storage\\BBYIKCGA\\Bondarenko en Raghunathan - 2016 - Graphical and numerical diagnostic tools to assess.pdf;C\:\\Users\\4216318\\Zotero\\storage\\Q53PV2BZ\\sim.html}
}

@article{brandToolkitSASEvaluation2003,
  title = {A Toolkit in {{SAS}} for the Evaluation of Multiple Imputation Methods},
  author = {Brand, Jaap P. L. and van Buuren, Stef and Groothuis‐Oudshoorn, Karin and Gelsema, Edzard S.},
  date = {2003},
  journaltitle = {Statistica Neerlandica},
  volume = {57},
  number = {1},
  pages = {36--45},
  issn = {1467-9574},
  doi = {10.1111/1467-9574.00219},
  url = {http://onlinelibrary.wiley.com/doi/abs/10.1111/1467-9574.00219},
  urldate = {2019-11-27},
  abstract = {This paper outlines a strategy to validate multiple imputation methods. Rubin's criteria for proper multiple imputation are the point of departure. We describe a simulation method that yields insight into various aspects of bias and efficiency of the imputation process. We propose a new method for creating incomplete data under a general Missing At Random (MAR) mechanism. Software implementing the validation strategy is available as a SAS/IML module. The method is applied to investigate the behavior of polytomous regression imputation for categorical data.},
  langid = {english},
  keywords = {missing data mechanism,multiple imputation,proper imputation,simulation.},
  file = {C\:\\Users\\4216318\\Zotero\\storage\\VSXG993W\\1467-9574.html}
}

@article{brig03,
  title = {Missing.... Presumed at Random: Cost-Analysis of Incomplete Data},
  shorttitle = {Missing.... Presumed at Random},
  author = {Briggs, Andrew and Clark, Taane and Wolstenholme, Jane and Clarke, Philip},
  date = {2003},
  journaltitle = {Health Economics},
  volume = {12},
  number = {5},
  pages = {377--392},
  issn = {1099-1050},
  doi = {10.1002/hec.766},
  url = {http://onlinelibrary.wiley.com/doi/abs/10.1002/hec.766},
  urldate = {2019-10-06},
  abstract = {When collecting patient-level resource use data for statistical analysis, for some patients and in some categories of resource use, the required count will not be observed. Although this problem must arise in most reported economic evaluations containing patient-level data, it is rare for authors to detail how the problem was overcome. Statistical packages may default to handling missing data through a so-called ‘complete case analysis’, while some recent cost-analyses have appeared to favour an ‘available case’ approach. Both of these methods are problematic: complete case analysis is inefficient and is likely to be biased; available case analysis, by employing different numbers of observations for each resource use item, generates severe problems for standard statistical inference. Instead we explore imputation methods for generating ‘replacement’ values for missing data that will permit complete case analysis using the whole data set and we illustrate these methods using two data sets that had incomplete resource use information. Copyright © 2002 John Wiley \& Sons, Ltd.},
  langid = {english},
  keywords = {cost-analysis,economic evaluation,missing data},
  file = {C\:\\Users\\4216318\\Zotero\\storage\\69EUE4JH\\Briggs e.a. - 2003 - Missing.... presumed at random cost-analysis of i.pdf;C\:\\Users\\4216318\\Zotero\\storage\\LBI3Q8QB\\hec.html}
}

@article{buur06,
  title = {Fully Conditional Specification in Multivariate Imputation},
  author = {Buuren, S. Van and Brand, J. P. L. and Groothuis-Oudshoorn, C. G. M. and Rubin, D. B.},
  date = {2006-12-01},
  journaltitle = {Journal of Statistical Computation and Simulation},
  volume = {76},
  number = {12},
  pages = {1049--1064},
  publisher = {{Taylor \& Francis}},
  issn = {0094-9655},
  doi = {10.1080/10629360600810434},
  url = {https://doi.org/10.1080/10629360600810434},
  urldate = {2020-03-22},
  abstract = {The use of the Gibbs sampler with fully conditionally specified models, where the distribution of each variable given the other variables is the starting point, has become a popular method to create imputations in incomplete multivariate data. The theoretical weakness of this approach is that the specified conditional densities can be incompatible, and therefore the stationary distribution to which the Gibbs sampler attempts to converge may not exist. This study investigates practical consequences of this problem by means of simulation. Missing data are created under four different missing data mechanisms. Attention is given to the statistical behavior under compatible and incompatible models. The results indicate that multiple imputation produces essentially unbiased estimates with appropriate coverage in the simple cases investigated, even for the incompatible models. Of particular interest is that these results were produced using only five Gibbs iterations starting from a simple draw from observed marginal distributions. It thus appears that, despite the theoretical weaknesses, the actual performance of conditional model specification for multivariate imputation can be quite good, and therefore deserves further study.},
  keywords = {Distributional compatibility,Gibbs sampling,Multiple imputation,Multivariate missing data,Proper imputation,Simulation},
  annotation = {\_eprint: https://doi.org/10.1080/10629360600810434},
  file = {C\:\\Users\\4216318\\Zotero\\storage\\YQ2Q2H3J\\Buuren e.a. - 2006 - Fully conditional specification in multivariate im.pdf;C\:\\Users\\4216318\\Zotero\\storage\\5VUVSNA2\\10629360600810434.html}
}

@book{buur18,
  title = {Flexible Imputation of Missing Data},
  author = {Van Buuren, Stef},
  date = {2018},
  publisher = {{Chapman and Hall/CRC}},
  url = {https://stefvanbuuren.name/fimd/}
}

@online{ChallengeMissingUncertain,
  title = {The {{Challenge}} of {{Missing}} and {{Uncertain Data}}},
  url = {https://www-computer-org.proxy.library.uu.nl/csdl/proceedings-article/ieee-vis/2003/20300100/12OmNrYCXRv},
  urldate = {2021-10-26},
  file = {C\:\\Users\\4216318\\Zotero\\storage\\Q9UNHQ2T\\12OmNrYCXRv.html}
}

@software{cutlerRandomForestBreimanCutler2018,
  title = {{{randomForest}}: Breiman and {{Cutler}}'s {{Random Forests}} for {{Classification}} and {{Regression}}},
  shorttitle = {{{randomForest}}},
  author = {Cutler, Fortran original by Leo Breiman {and} Adele and Wiener, R. port by Andy Liaw {and} Matthew},
  date = {2018-03-25},
  url = {https://CRAN.R-project.org/package=randomForest},
  urldate = {2021-09-16},
  abstract = {Classification and regression based on a forest of trees using random inputs, based on Breiman (2001) {$<$}doi:10.1023/A:1010933404324{$>$}.},
  version = {4.6-14},
  keywords = {Environmetrics,MachineLearning,MissingData},
  file = {C\:\\Users\\4216318\\Zotero\\storage\\4X5MQX2Q\\randomForest.pdf;C\:\\Users\\4216318\\Zotero\\storage\\V486H5CL\\Using_random_forests_v4.0.pdf}
}

@inproceedings{eatonVisualizingMissingData2005,
  title = {Visualizing {{Missing Data}}: Graph {{Interpretation User Study}}},
  shorttitle = {Visualizing {{Missing Data}}},
  booktitle = {Human-{{Computer Interaction}} - {{INTERACT}} 2005},
  author = {Eaton, Cyntrica and Plaisant, Catherine and Drizd, Terence},
  editor = {Costabile, Maria Francesca and Paternò, Fabio},
  date = {2005},
  series = {Lecture {{Notes}} in {{Computer Science}}},
  pages = {861--872},
  publisher = {{Springer}},
  location = {{Berlin, Heidelberg}},
  doi = {10.1007/11555261_68},
  abstract = {Most visualization tools fail to provide support for missing data. In this paper, we identify sources of missing data and describe three levels of impact missing data can have on the visualization: perceivable, invisible or propagating. We then report on a user study with 30 participants that compared three design variants. A between-subject graph interpretation study provides strong evidence for the need of indicating the presence of missing information, and some direction for addressing the problem.},
  isbn = {978-3-540-31722-7},
  langid = {english},
  file = {C\:\\Users\\4216318\\Zotero\\storage\\I37UYHN4\\Eaton et al. - 2005 - Visualizing Missing Data Graph Interpretation Use.pdf}
}

@inproceedings{eatonVisualizingMissingData2005a,
  title = {Visualizing {{Missing Data}}: Graph {{Interpretation User Study}}},
  shorttitle = {Visualizing {{Missing Data}}},
  booktitle = {Human-{{Computer Interaction}} - {{INTERACT}} 2005},
  author = {Eaton, Cyntrica and Plaisant, Catherine and Drizd, Terence},
  editor = {Costabile, Maria Francesca and Paternò, Fabio},
  date = {2005},
  series = {Lecture {{Notes}} in {{Computer Science}}},
  pages = {861--872},
  publisher = {{Springer}},
  location = {{Berlin, Heidelberg}},
  doi = {10.1007/11555261_68},
  abstract = {Most visualization tools fail to provide support for missing data. In this paper, we identify sources of missing data and describe three levels of impact missing data can have on the visualization: perceivable, invisible or propagating. We then report on a user study with 30 participants that compared three design variants. A between-subject graph interpretation study provides strong evidence for the need of indicating the presence of missing information, and some direction for addressing the problem.},
  isbn = {978-3-540-31722-7},
  langid = {english},
  file = {C\:\\Users\\4216318\\Zotero\\storage\\H35AII9H\\Eaton et al. - 2005 - Visualizing Missing Data Graph Interpretation Use.pdf}
}

@book{ende10,
  ids = {endersAppliedMissingData2010,endersAppliedMissingData2010a},
  title = {Applied Missing Data Analysis},
  author = {Enders, Craig K},
  date = {2010},
  publisher = {{Guilford press}},
  isbn = {1-60623-639-3},
  file = {C\:\\Users\\4216318\\Zotero\\storage\\4FBHSPM9\\Enders - 2010 - Applied missing data analysis.pdf;C\:\\Users\\4216318\\Zotero\\storage\\GTM2QHJI\\Enders - 2010 - Applied missing data analysis.pdf;C\:\\Users\\4216318\\Zotero\\storage\\95RQIU7H\\books.html}
}

@article{ende18,
  title = {A Fully Conditional Specification Approach to Multilevel Imputation of Categorical and Continuous Variables.},
  author = {Enders, Craig K. and Keller, Brian T. and Levy, Roy},
  date = {2018-06},
  journaltitle = {Psychological Methods},
  shortjournal = {Psychological Methods},
  volume = {23},
  number = {2},
  pages = {298--317},
  issn = {1939-1463, 1082-989X},
  doi = {10.1037/met0000148},
  url = {http://doi.apa.org/getdoi.cfm?doi=10.1037/met0000148},
  urldate = {2019-09-19},
  abstract = {Specialized imputation routines for multilevel data are widely available in software packages, but these methods are generally not equipped to handle a wide range of complexities that are typical of behavioral science data. In particular, existing imputation schemes differ in their ability to handle random slopes, categorical variables, differential relations at level-1 and level-2, and incomplete level-2 variables. Given the limitations of existing imputation tools, the purpose of this manuscript is to describe a flexible imputation approach that can accommodate a diverse set of two-level analysis problems that includes any of the aforementioned features. The procedure employs a fully conditional specification (also known as chained equations) approach with a latent variable formulation for handling incomplete categorical variables. Computer simulations suggest that the proposed procedure works quite well, with trivial biases in most cases. We provide a software program that implements the imputation strategy, and we use an artificial data set to illustrate its use.},
  langid = {english},
  file = {C\:\\Users\\4216318\\Zotero\\storage\\J2H75436\\enders-keller--levy-2017--.pdf}
}

@article{fichmanMultipleImputationMissing2003,
  title = {Multiple {{Imputation}} for {{Missing Data}}: Making the Most of {{What}} You {{Know}}},
  shorttitle = {Multiple {{Imputation}} for {{Missing Data}}},
  author = {Fichman, Mark and Cummings, Jonathon N.},
  date = {2003-07-01},
  journaltitle = {Organizational Research Methods},
  shortjournal = {Organizational Research Methods},
  volume = {6},
  number = {3},
  pages = {282--308},
  publisher = {{SAGE Publications Inc}},
  issn = {1094-4281},
  doi = {10.1177/1094428103255532},
  url = {https://doi.org/10.1177/1094428103255532},
  urldate = {2020-03-04},
  abstract = {Missing data are a common problem in organizational research. Missing data can occur due to attrition in a longitudinal study or nonresponse to questionnaire items in a laboratory or field setting. Improper treatments of missing data (e.g., listwise deletion, mean imputation) can lead to biased statistical inference using complete case analysis statistical techniques. This article presents a simulation and data analysis case study using a method for dealing with missing data, multiple imputation, that allows for valid statistical inference with complete case statistical analysis. Software for implementing multiple imputation under a multivariate normal model is freely and widely available (e.g., NORM, SAS, SOLAS). It should be routinely considered for imputing missing data. The authors illustrate the application of this technique using data from the HomeNet project.},
  file = {C\:\\Users\\4216318\\Zotero\\storage\\QTIV6ICE\\Fichman en Cummings - 2003 - Multiple Imputation for Missing Data Making the m.pdf}
}

@online{FullyConditionalSpecification,
  title = {Fully Conditional Specification in Multivariate Imputation: Journal of {{Statistical Computation}} and {{Simulation}}: Vol 76, {{No}} 12},
  url = {https://www-tandfonline-com.proxy.library.uu.nl/doi/full/10.1080/10629360600810434},
  urldate = {2020-03-22},
  file = {C\:\\Users\\4216318\\Zotero\\storage\\F4Y9QAE9\\10629360600810434.html}
}

@article{gelm92,
  title = {Inference from {{Iterative Simulation Using Multiple Sequences}}},
  author = {Gelman, Andrew and Rubin, Donald B.},
  date = {1992-11},
  journaltitle = {Statistical Science},
  shortjournal = {Statist. Sci.},
  volume = {7},
  number = {4},
  pages = {457--472},
  doi = {10.1214/ss/1177011136},
  abstract = {The Gibbs sampler, the algorithm of Metropolis and similar iterative simulation methods are potentially very helpful for summarizing multivariate distributions. Used naively, however, iterative simulation can give misleading answers. Our methods are simple and generally applicable to the output of any iterative simulation; they are designed for researchers primarily interested in the science underlying the data and models they are analyzing, rather than for researchers interested in the probability theory underlying the iterative simulations themselves. Our recommended strategy is to use several independent sequences, with starting points sampled from an overdispersed distribution. At each step of the iterative simulation, we obtain, for each univariate estimand of interest, a distributional estimate and an estimate of how much sharper the distributional estimate might become if the simulations were continued indefinitely. Because our focus is on applied inference for Bayesian posterior distributions in real problems, which often tend toward normality after transformations and marginalization, we derive our results as normal-theory approximations to exact Bayesian inference, conditional on the observed simulations. The methods are illustrated on a random-effects mixture model applied to experimental measurements of reaction times of normal and schizophrenic patients.},
  langid = {english},
  zmnumber = {06853057},
  keywords = {Bayesian inference,convergence of stochastic processes,ECM,EM,Gibbs sampler,importance sampling,Metropolis algorithm,multiple imputation,random-effects model,SIR},
  file = {C\:\\Users\\4216318\\Zotero\\storage\\CWG9QXQK\\Gelman en Rubin - 1992 - Inference from Iterative Simulation Using Multiple.pdf;C\:\\Users\\4216318\\Zotero\\storage\\EK2UCSZT\\1177011136.html}
}

@incollection{gelmanMissingdataImputation2006,
  title = {Missing-Data Imputation},
  booktitle = {Data {{Analysis Using Regression}} and {{Multilevel}}/{{Hierarchical Models}}},
  editor = {Gelman, Andrew and Hill, Jennifer},
  date = {2006},
  series = {Analytical {{Methods}} for {{Social Research}}},
  pages = {529--544},
  publisher = {{Cambridge University Press}},
  location = {{Cambridge}},
  doi = {10.1017/CBO9780511790942.031},
  url = {https://www.cambridge.org/core/books/data-analysis-using-regression-and-multilevelhierarchical-models/missingdata-imputation/96352AB9B4A9534FDBE5F4A0D3EBF220},
  urldate = {2021-05-27},
  isbn = {978-0-521-86706-1},
  file = {C\:\\Users\\4216318\\Zotero\\storage\\GDP6GWI4\\Gelman and Hill - 2006 - Missing-data imputation.pdf}
}

@online{GenerateMissingValues,
  title = {Generate Missing Values with Ampute},
  url = {https://www.gerkovink.com/Amputation_with_Ampute/Vignette/ampute.html},
  urldate = {2020-03-04},
  file = {C\:\\Users\\4216318\\Zotero\\storage\\I7RBXQPI\\ampute.html}
}

@online{GeneratingMissingValues,
  title = {Generating Missing Values for Simulation Purposes: A Multivariate Amputation Procedure: Journal of {{Statistical Computation}} and {{Simulation}}: Vol 88, {{No}} 15},
  url = {https://www.tandfonline.com/doi/full/10.1080/00949655.2018.1491577},
  urldate = {2020-03-04},
  file = {C\:\\Users\\4216318\\Zotero\\storage\\J75JCK6X\\00949655.2018.html}
}

@book{grah12,
  ids = {grahamMissingDataAnalysis2012,grahamMissingDataAnalysis2012a},
  title = {Missing Data: Analysis and Design},
  author = {Graham, John W},
  date = {2012},
  publisher = {{Springer Science \& Business Media}},
  doi = {10.1007/978-1-4614-4018-5},
  isbn = {1-4614-4018-1},
  file = {C\:\\Users\\4216318\\Zotero\\storage\\688F2XST\\Graham - 2012 - Missing data Analysis and design.pdf;C\:\\Users\\4216318\\Zotero\\storage\\6ZKJ7Q94\\Graham - 2012 - Missing Data Analysis and Design.pdf;C\:\\Users\\4216318\\Zotero\\storage\\8RY4LBWA\\books.html;C\:\\Users\\4216318\\Zotero\\storage\\AK9W2NIN\\9781461440178.html}
}

@book{grietheVisualizingUncertaintyImproved2005,
  title = {Visualizing Uncertainty for Improved Decision Making},
  author = {Griethe, H and Schumann, Heidrun},
  date = {2005-01-01},
  journaltitle = {Proceedings of the 4th International Conference on Business Informatics Research, BIR 2005},
  volume = {2005},
  abstract = {Decision making often depends on the analysis and evaluation of large amounts of data for which information visualization proved to be a valuable approach. The recognition of uncertainty in the data is crucial and it should therefore be appropriately represented. However, suitable methods for its visualization are in many cases not available. This paper provides a general view on uncertainty with respect to a widely accepted information model. Out of this view it explains why the recognition of uncertainty plays an important role for decisions, and it depicts available but especially missing visualization concepts today, e.g. for the display of uncertain relationships. To fill that gap new ideas are derived for an improved visual decision support.}
}

@article{harelEstimationAdjustedIncomplete2009,
  title = {The Estimation of {{R}} 2 and Adjusted {{R}} 2 in Incomplete Data Sets Using Multiple Imputation},
  author = {Harel, Ofer},
  date = {2009-10-01},
  journaltitle = {Journal of Applied Statistics},
  volume = {36},
  number = {10},
  pages = {1109--1118},
  publisher = {{Taylor \& Francis}},
  issn = {0266-4763},
  doi = {10.1080/02664760802553000},
  url = {https://doi.org/10.1080/02664760802553000},
  urldate = {2020-03-16},
  abstract = {The coefficient of determination, known also as the R 2, is a common measure in regression analysis. Many scientists use the R 2 and the adjusted R 2 on a regular basis. In most cases, the researchers treat the coefficient of determination as an index of ‘usefulness’ or ‘goodness of fit,’ and in some cases, they even treat it as a model selection tool. In cases in which the data is incomplete, most researchers and common statistical software will use complete case analysis in order to estimate the R 2, a procedure that might lead to biased results. In this paper, I introduce the use of multiple imputation for the estimation of R 2 and adjusted R 2 in incomplete data sets. I illustrate my methodology using a biomedical example.},
  keywords = {coefficient of determination,incomplete data,linear regression,multiple imputation},
  annotation = {\_eprint: https://doi.org/10.1080/02664760802553000},
  file = {C\:\\Users\\4216318\\Zotero\\storage\\XKMGHWUF\\Harel - 2009 - The estimation of R 2 and adjusted R 2 in incomple.pdf;C\:\\Users\\4216318\\Zotero\\storage\\9GZA2JEG\\02664760802553000.html}
}

@online{HelloSketchSketch,
  title = {Hello from {{Sketch}} | {{Sketch}}},
  url = {https://kcf-jackson.github.io/sketch-website/},
  urldate = {2021-10-26},
  abstract = {Description will go into a meta tag in {$<$}head /{$>$}},
  langid = {english},
  file = {C\:\\Users\\4216318\\Zotero\\storage\\SKH6XSEW\\sketch-website.html}
}

@article{hortonMultipleImputationPractice2001,
  title = {Multiple {{Imputation}} in {{Practice}}: Comparison of {{Software Packages}} for {{Regression Models With Missing Variables}}},
  shorttitle = {Multiple {{Imputation}} in {{Practice}}},
  author = {Horton, Nicholas J and Lipsitz, Stuart R},
  date = {2001-08},
  journaltitle = {The American Statistician},
  shortjournal = {The American Statistician},
  volume = {55},
  number = {3},
  pages = {244--254},
  issn = {0003-1305, 1537-2731},
  doi = {10.1198/000313001317098266},
  url = {http://www.tandfonline.com/doi/abs/10.1198/000313001317098266},
  urldate = {2020-03-04},
  langid = {english},
  file = {C\:\\Users\\4216318\\Zotero\\storage\\RCIXUG22\\Horton en Lipsitz - 2001 - Multiple Imputation in Practice Comparison of Sof.pdf}
}

@report{lace07,
  title = {Sequential Regression Multiple Imputation for Incomplete Multivariate Data Using {{Markov}} Chain {{Monte Carlo}}},
  author = {Lacerda, Miguel and Ardington, Cally and Leibbrandt, Murray},
  date = {2007},
  institution = {{University of Cape Town, South Africa}},
  file = {C\:\\Users\\4216318\\Zotero\\storage\\NIKK7HSY\\2008_13.pdf}
}

@article{li14,
  title = {Multiple {{Imputation}} by {{Ordered Monotone Blocks With Application}} to the {{Anthrax Vaccine Research Program}}},
  author = {Li, Fan and Baccini, Michela and Mealli, Fabrizia and Zell, Elizabeth R. and Frangakis, Constantine E. and Rubin, Donald B.},
  date = {2014-07-03},
  journaltitle = {Journal of Computational and Graphical Statistics},
  shortjournal = {Journal of Computational and Graphical Statistics},
  volume = {23},
  number = {3},
  pages = {877--892},
  issn = {1061-8600},
  doi = {10.1080/10618600.2013.826583},
  url = {https://www.tandfonline.com/doi/10.1080/10618600.2013.826583},
  urldate = {2019-09-10},
  abstract = {Multiple imputation (MI) has become a standard statistical technique for dealing with missing values. The CDC Anthrax Vaccine Research Program (AVRP) dataset created new challenges for MI due to the large number of variables of different types and the limited sample size. A common method for imputing missing data in such complex studies is to specify, for each of J variables with missing values, a univariate conditional distribution given all other variables, and then to draw imputations by iterating over the J conditional distributions. Such fully conditional imputation strategies have the theoretical drawback that the conditional distributions may be incompatible. When the missingness pattern is monotone, a theoretically valid approach is to specify, for each variable with missing values, a conditional distribution given the variables with fewer or the same number of missing values and sequentially draw from these distributions. In this article, we propose the “multiple imputation by ordered monotone blocks” approach, which combines these two basic approaches by decomposing any missingness pattern into a collection of smaller “constructed” monotone missingness patterns, and iterating. We apply this strategy to impute the missing data in the AVRP interim data. Supplemental materials, including all source code and a synthetic example dataset, are available online.},
  file = {C\:\\Users\\4216318\\Zotero\\storage\\Z2SXCLDC\\Li e.a. - 2014 - Multiple Imputation by Ordered Monotone Blocks Wit.pdf;C\:\\Users\\4216318\\Zotero\\storage\\PUZN3HTY\\10618600.2013.html}
}

@article{li91,
  title = {Significance Levels from Repeated P-Values with Multiply-Imputed Data},
  author = {Li, Kim-Hung and Meng, Xiao-Li and Raghunathan, Trivellore E and Rubin, Donald B},
  date = {1991},
  journaltitle = {Statistica Sinica},
  shortjournal = {Statistica Sinica},
  pages = {65--92},
  issn = {1017-0405},
  file = {C\:\\Users\\4216318\\Zotero\\storage\\3KXYTRMF\\Li Meng Raghunathan Rubin - combining p values.pdf}
}

@book{littleStatisticalAnalysisMissing2002,
  title = {Statistical {{Analysis}} with {{Missing Data}}},
  author = {Little, Roderick J. A. and Rubin, Donald B.},
  date = {2002},
  edition = {1},
  publisher = {{John Wiley \& Sons, Ltd}},
  doi = {10.1002/9781119013563},
  url = {http://onlinelibrary.wiley.com/doi/10.1002/9781119013563},
  urldate = {2021-09-23},
  annotation = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/9781119013563},
  file = {C\:\\Users\\4216318\\Zotero\\storage\\INEERPWF\\9781119013563.html}
}

@article{liuStationaryDistributionIterative,
  ids = {liu14,liuStationaryDistributionIterative2014},
  title = {On the {{Stationary Distribution}} of {{Iterative Imputations}}},
  author = {Liu, Jingchen and Gelman, Andrew},
  pages = {18},
  publisher = {{[Oxford University Press, Biometrika Trust]}},
  abstract = {Iterative imputation, in which variables are imputed one at a time conditional on all the oth- 15 ers, is a popular technique that can be convenient and flexible, as it replaces a potentially difficult multivariate modeling problem with relatively simple univariate regressions. In this paper, we begin to characterize the stationary distributions of iterative imputations and their statistical properties, accounting for the conditional models being iteratively estimated from data rather than being pre-specified. When the families of conditional models are compatible, we provide 20 sufficient conditions under which the imputation distribution converges in total variation to the posterior distribution of a Bayesian model. When the conditional models are incompatible but valid, we show that the combined imputation estimator is consistent.},
  langid = {english},
  file = {C\:\\Users\\4216318\\Zotero\\storage\\5BFL93ME\\Liu e.a. - 2014 - On the stationary distribution of iterative imputa.pdf;C\:\\Users\\4216318\\Zotero\\storage\\QCDVMXA6\\Liu and Gelman - On the Stationary Distribution of Iterative Imputa.pdf}
}

@article{meng94,
  title = {Multiple-{{Imputation Inferences}} with {{Uncongenial Sources}} of {{Input}}},
  author = {Meng, Xiao-Li},
  date = {1994-11},
  journaltitle = {Statistical Science},
  shortjournal = {Statist. Sci.},
  volume = {9},
  number = {4},
  pages = {538--558},
  issn = {0883-4237, 2168-8745},
  doi = {10.1214/ss/1177010269},
  url = {https://projecteuclid.org/euclid.ss/1177010269},
  urldate = {2019-10-03},
  abstract = {Conducting sample surveys, imputing incomplete observations, and analyzing the resulting data are three indispensable phases of modern practice with public-use data files and with many other statistical applications. Each phase inherits different input, including the information preceding it and the intellectual assessments available, and aims to provide output that is one step closer to arriving at statistical inferences with scientific relevance. However, the role of the imputation phase has often been viewed as merely providing computational convenience for users of data. Although facilitating computation is very important, such a viewpoint ignores the imputer's assessments and information inaccessible to the users. This view underlies the recent controversy over the validity of multiple-imputation inference when a procedure for analyzing multiply imputed data sets cannot be derived from (is "uncongenial" to) the model adopted for multiple imputation. Given sensible imputations and complete-data analysis procedures, inferences from standard multiple-imputation combining rules are typically superior to, and thus different from, users' incomplete-data analyses. The latter may suffer from serious nonresponse biases because such analyses often must rely on convenient but unrealistic assumptions about the nonresponse mechanism. When it is desirable to conduct inferences under models for nonresponse other than the original imputation model, a possible alternative to recreating imputations is to incorporate appropriate importance weights into the standard combining rules. These points are reviewed and explored by simple examples and general theory, from both Bayesian and frequentist perspectives, particularly from the randomization perspective. Some convenient terms are suggested for facilitating communication among researchers from different perspectives when evaluating multiple-imputation inferences with uncongenial sources of input.},
  langid = {english},
  keywords = {Congeniality,importance sampling,incomplete data,missing data,nonresponse,normalizing constants,public-use data file,randomization,self-efficiency},
  file = {C\:\\Users\\4216318\\Zotero\\storage\\LDSDEUAS\\Meng - 1994 - Multiple-Imputation Inferences with Uncongenial So.pdf;C\:\\Users\\4216318\\Zotero\\storage\\PHA35LD7\\Meng - 1994 - Multiple-Imputation Inferences with Uncongenial So.pdf;C\:\\Users\\4216318\\Zotero\\storage\\MNNUQRPL\\1177010269.html}
}

@article{mice,
  title = {Mice: Multivariate {{Imputation}} by {{Chained Equations}} in {{R}}},
  shorttitle = {Mice},
  author = {Van Buuren, Stef and Groothuis-Oudshoorn, Karin},
  date = {2011-12-12},
  journaltitle = {Journal of Statistical Software},
  volume = {45},
  number = {1},
  pages = {1--67},
  doi = {10.18637/jss.v045.i03},
  langid = {english},
  file = {C\:\\Users\\4216318\\Zotero\\storage\\W7DXJIVB\\Buuren en Groothuis-Oudshoorn - 2011 - mice Multivariate Imputation by Chained Equations.pdf;C\:\\Users\\4216318\\Zotero\\storage\\6GARXLG6\\v045i03.html}
}

@article{morr19,
  title = {Using Simulation Studies to Evaluate Statistical Methods},
  author = {Morris, Tim P. and White, Ian R. and Crowther, Michael J.},
  date = {2019-05-20},
  journaltitle = {Statistics in Medicine},
  volume = {38},
  number = {11},
  pages = {2074--2102},
  publisher = {{John Wiley \& Sons, Ltd}},
  issn = {1097-0258},
  doi = {10.1002/sim.8086},
  url = {http://onlinelibrary.wiley.com/doi/10.1002/sim.8086},
  urldate = {2020-04-16},
  abstract = {Simulation studies are computer experiments that involve creating data by pseudo‐random sampling. A key strength of simulation studies is the ability to understand the behavior of statistical methods...},
  langid = {english},
  file = {C\:\\Users\\4216318\\Zotero\\storage\\C2X36276\\Morris e.a. - 2019 - Using simulation studies to evaluate statistical m.pdf;C\:\\Users\\4216318\\Zotero\\storage\\LN3P265W\\login.html}
}

@article{murr18,
  ids = {murrayMultipleImputationReview2018},
  title = {Multiple {{Imputation}}: A {{Review}} of {{Practical}} and {{Theoretical Findings}}},
  shorttitle = {Multiple {{Imputation}}},
  author = {Murray, Jared S.},
  date = {2018-05},
  journaltitle = {Statistical Science},
  shortjournal = {Statist. Sci.},
  volume = {33},
  number = {2},
  eprint = {1801.04058},
  eprinttype = {arxiv},
  pages = {142--159},
  doi = {10.1214/18-STS644},
  abstract = {Multiple imputation is a straightforward method for handling missing data in a principled fashion. This paper presents an overview of multiple imputation, including important theoretical results and their practical implications for generating and using multiple imputations. A review of strategies for generating imputations follows, including recent developments in flexible joint modeling and sequential regression/chained equations/fully conditional specification approaches. Finally, we compare and contrast different methods for generating imputations on a range of criteria before identifying promising avenues for future research.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Statistics - Methodology},
  file = {C\:\\Users\\4216318\\Zotero\\storage\\QTYJEWQ2\\Murray - 2018 - Multiple Imputation A Review of Practical and The.pdf;C\:\\Users\\4216318\\Zotero\\storage\\TT9QUVIH\\Murray - 2018 - Multiple Imputation A Review of Practical and The.pdf;C\:\\Users\\4216318\\Zotero\\storage\\A7M2FZYH\\1801.html}
}

@article{neym34,
  title = {On the {{Two Different Aspects}} of the {{Representative Method}}: The {{Method}} of {{Stratified Sampling}} and the {{Method}} of {{Purposive Selection}}},
  author = {Neyman, Jerzy},
  date = {1934},
  journaltitle = {Journal of the Royal Statistical Society},
  volume = {97},
  number = {4},
  pages = {558--625},
  doi = {10.2307/2342192},
  file = {C\:\\Users\\4216318\\Zotero\\storage\\ZMX9KJKR\\Neyman - 1934 - On the Two Different Aspects of the Representative.pdf}
}

@article{nguy17,
  ids = {nguyenModelCheckingMultiple2017,nguyenModelCheckingMultiple2017a},
  title = {Model Checking in Multiple Imputation: An Overview and Case Study},
  shorttitle = {Model Checking in Multiple Imputation},
  author = {Nguyen, Cattram D. and Carlin, John B. and Lee, Katherine J.},
  date = {2017-08-23},
  journaltitle = {Emerging Themes in Epidemiology},
  shortjournal = {Emerging Themes in Epidemiology},
  volume = {14},
  number = {1},
  eprint = {28852415},
  eprinttype = {pmid},
  pages = {8},
  issn = {1742-7622},
  doi = {10.1186/s12982-017-0062-6},
  url = {https://doi.org/10.1186/s12982-017-0062-6},
  urldate = {2019-09-27},
  abstract = {Multiple imputation has become very popular as a general-purpose method for handling missing data. The validity of multiple-imputation-based analyses relies on the use of an appropriate model to impute the missing values. Despite the widespread use of multiple imputation, there are few guidelines available for checking imputation models.},
  pmcid = {PMC5569512},
  keywords = {Cross-validation,Diagnostics,Missing data,Model checking,Multiple imputation,Posterior predictive checking},
  file = {C\:\\Users\\4216318\\Zotero\\storage\\292299YB\\Nguyen et al. - 2017 - Model checking in multiple imputation an overview.pdf;C\:\\Users\\4216318\\Zotero\\storage\\GNUQEAQA\\Nguyen e.a. - 2017 - Model checking in multiple imputation an overview.pdf;C\:\\Users\\4216318\\Zotero\\storage\\CDXNKIZY\\s12982-017-0062-6.html;C\:\\Users\\4216318\\Zotero\\storage\\LCHBMRXB\\s12982-017-0062-6.html}
}

@inproceedings{obermanMissingPointNonConvergence,
  ids = {obermanMissingPointNonConvergence2020},
  title = {Missing the {{Point}}: Non-{{Convergence}} in {{Iterative Imputation Algorithms}}},
  author = {Oberman, Hanne I},
  pages = {4},
  abstract = {Iterative imputation is a popular tool to accommodate missing data. While it is widely accepted that valid inferences can be obtained with this technique, these inferences all rely on algorithmic convergence. There is no consensus on how to evaluate the convergence properties of the method. Our study provides insight into identifying non-convergence in iterative imputation algorithms. We found that—in the cases considered—inferential validity was achieved after five to ten iterations, much earlier than indicated by diagnostic methods. We conclude that it never hurts to iterate longer, but such calculations hardly bring added value.},
  langid = {english},
  file = {C\:\\Users\\4216318\\Zotero\\storage\\8CS6UMYW\\Oberman - Missing the Point Non-Convergence in Iterative Im.pdf;C\:\\Users\\4216318\\Zotero\\storage\\LKMBAJSG\\Oberman et al. - 2020 - Missing the Point Non-Convergence in Iterative Im.pdf;C\:\\Users\\4216318\\Zotero\\storage\\5HH4DJVT\\forum.html}
}

@book{R,
  ids = {rcoreteamLanguageEnvironmentStatistical2020},
  title = {R: A Language and Environment for Statistical Computing},
  author = {{R Core Team}},
  date = {2020},
  location = {{Vienna, Austria}},
  organization = {{R Foundation for Statistical Computing}}
}

@article{ragh01,
  title = {A Multivariate Technique for Multiply Imputing Missing Values Using a Sequence of Regression Models},
  author = {Raghunathan, Trivellore E and Lepkowski, James M and Van Hoewyk, John and Solenberger, Peter},
  date = {2001},
  journaltitle = {Survey methodology},
  shortjournal = {Survey methodology},
  volume = {27},
  number = {1},
  pages = {85--96},
  issn = {0714-0045},
  file = {C\:\\Users\\4216318\\Zotero\\storage\\ZF27VSE7\\Raghunathan e.a. - 2001 - A multivariate technique for multiply imputing mis.pdf}
}

@report{ragh07,
  type = {SSRN Scholarly Paper},
  title = {Diagnostics for {{Multiple Imputations}}},
  author = {Raghunathan, Trivellore and Bondarenko, Irina},
  date = {2007-11-21},
  number = {ID 1031750},
  institution = {{Social Science Research Network}},
  location = {{Rochester, NY}},
  url = {https://papers.ssrn.com/abstract=1031750},
  urldate = {2019-10-17},
  abstract = {Multiple imputation technique is becoming a popular method for analyzing data with missing values. Several methods have been proposed for creating multiple imputations and most of these methods assume that the data are missing at random (MAR). However, limited diagnostic tools are available to check whether the imputations created by these methods are reasonable. This article develops a set of diagnostic tools based on certain conditional distributions of the observed and imputed values. These conditional distributions should be similar if the assumed model for creating multiple imputations is a good fit. The tools are formulated in terms of numerical summaries and graphical displays and could be easily implemented using the standard complete data software packages. For implementing these methods the exact nature of the model used by the imputer is not needed. The method is illustrated using a data set with large number of variables of different types with varying amount of missing values.},
  langid = {english},
  keywords = {Congeniality,Diagnostics,Missing at Random,Propensity score matching},
  file = {C\:\\Users\\4216318\\Zotero\\storage\\WL7ZL76E\\Raghunathan en Bondarenko - 2007 - Diagnostics for Multiple Imputations.pdf}
}

@article{rubin04,
  title = {The {{Design}} of a {{General}} and {{Flexible System}} for {{Handling Nonresponse}} in {{Sample Surveys}}},
  author = {Rubin, Donald B},
  date = {2004-11-01},
  journaltitle = {The American Statistician},
  shortjournal = {The American Statistician},
  volume = {58},
  number = {4},
  pages = {298--302},
  doi = {10.1198/000313004X6355},
  url = {https://amstat.tandfonline.com/doi/abs/10.1198/000313004X6355},
  urldate = {2019-10-01},
  file = {C\:\\Users\\4216318\\Zotero\\storage\\RJ2HAQHD\\Rubin - 2004 - The Design of a General and Flexible System for Ha.pdf;C\:\\Users\\4216318\\Zotero\\storage\\EN6WGCA4\\000313004X6355.html}
}

@article{rubin76,
  title = {Inference and {{Missing Data}}},
  author = {Rubin, Donald B.},
  date = {1976},
  journaltitle = {Biometrika},
  volume = {63},
  number = {3},
  pages = {581--592},
  doi = {10.2307/2335739},
  abstract = {When making sampling distribution inferences about the parameter of the data, θ, it is appropriate to ignore the process that causes missing data if the missing data are `missing at random' and the observed data are `observed at random', but these inferences are generally conditional on the observed pattern of missing data. When making direct-likelihood or Bayesian inferences about θ, it is appropriate to ignore the process that causes missing data if the missing data are missing at random and the parameter of the missing data process is `distinct' from θ. These conditions are the weakest general conditions under which ignoring the process that causes missing data always leads to correct inferences.}
}

@book{rubin87,
  title = {Multiple {{Imputation}} for Nonresponse in Surveys},
  author = {Rubin, Donald B.},
  date = {1987},
  series = {Wiley Series in Probability and Mathematical Statistics {{Applied}} Probability and Statistics},
  publisher = {{Wiley}},
  location = {{New York, NY}},
  langid = {english},
  pagetotal = {258},
  file = {C\:\\Users\\4216318\\Zotero\\storage\\63UKR3PY\\Rubin - 1987 - Multiple Imputation for nonresponse in surveys.pdf}
}

@article{rubin96,
  title = {Multiple {{Imputation After}} 18+ {{Years}}},
  author = {Rubin, Donald B.},
  date = {1996},
  journaltitle = {Journal of the American Statistical Association},
  volume = {91},
  number = {434},
  pages = {473--489},
  doi = {10.2307/2291635},
  abstract = {[Multiple imputation was designed to handle the problem of missing data in public-use data bases where the data-base constructor and the ultimate user are distinct entities. The objective is valid frequency inference for ultimate users who in general have access only to complete-data software and possess limited knowledge of specific reasons and models for nonresponse. For this situation and objective, I believe that multiple imputation by the data-base constructor is the method of choice. This article first provides a description of the assumed context and objectives, and second, reviews the multiple imputation framework and its standard results. These preliminary discussions are especially important because some recent commentaries on multiple imputation have reflected either misunderstandings of the practical objectives of multiple imputation or misunderstandings of fundamental theoretical results. Then, criticisms of multiple imputation are considered, and, finally, comparisons are made to alternative strategies.]},
  file = {C\:\\Users\\4216318\\Zotero\\storage\\9UVT28MF\\Rubin - Multiple Imputation after 18+ years.pdf}
}

@article{sas14,
  title = {Sensitivity {{Analysis}} in {{Multiple Imputation}} for {{Missing Data}}},
  author = {Yuan, Yang},
  journaltitle = {In Proceedings of the SAS Global Forum 2014 Conference},
  abstract = {Multiple imputation, a popular strategy for dealing with missing values, usually assumes that the data are missing at random (MAR). That is, for a variable Y, the probability that an observation is missing depends only on the observed values of other variables, not on the unobserved values of Y. It is important to examine the sensitivity of inferences to departures from the MAR assumption, because this assumption cannot be verified using the data.},
  langid = {english},
  file = {C\:\\Users\\4216318\\Zotero\\storage\\NQKZC84X\\Yuan - Sensitivity Analysis in Multiple Imputation for Mi.pdf}
}

@article{scha02,
  title = {Missing Data: Our View of the State of the Art.},
  author = {Schafer, Joseph L and Graham, John W},
  date = {2002},
  journaltitle = {Psychological methods},
  shortjournal = {Psychological methods},
  volume = {7},
  number = {2},
  pages = {147},
  issn = {1939-1463},
  abstract = {Statistical procedures for missing data have vastly improved, yet misconception and unsound practice still abound. The authors frame the missing-data problem, review methods, offer advice, and raise issues that remain unresolved. They clear up common misunderstandings regarding the missing at random (MAR) concept. They summarize the evidence against older procedures and, with few exceptions, discourage their use. They present, in both technical and practical language, 2 general approaches that come highly recommended: maximum likelihood (ML) and Bayesian multiple imputation (MI). Newer developments are discussed, including some for dealing with missing data that are not MAR. Although not yet in the mainstream, these procedures may eventually extend the ML and MI methods that currently represent the state of the art},
  file = {C\:\\Users\\4216318\\Zotero\\storage\\RP4NJ9T2\\Schafer en Graham - 2002 - Missing data our view of the state of the art..pdf}
}

@book{scha97,
  title = {Analysis of Incomplete Multivariate Data},
  author = {Schafer, Joseph L},
  date = {1997},
  publisher = {{Chapman and Hall/CRC}},
  file = {C\:\\Users\\4216318\\Zotero\\storage\\Q7G6U2VV\\Schafer - 1997 - Analysis of incomplete multivariate data.pdf;C\:\\Users\\4216318\\Zotero\\storage\\VEI29NIR\\Schafer - 1997 - Analysis of incomplete multivariate data.pdf}
}

@article{schaferMultipleImputationMultivariate1998,
  ids = {schaferMultipleImputationMultivariate1998a},
  title = {Multiple {{Imputation}} for {{Multivariate Missing}}-{{Data Problems}}: A {{Data Analyst}}'s {{Perspective}}},
  shorttitle = {Multiple {{Imputation}} for {{Multivariate Missing}}-{{Data Problems}}},
  author = {Schafer, Joseph L. and Olsen, Maren K.},
  date = {1998-10-01},
  journaltitle = {Multivariate Behavioral Research},
  volume = {33},
  number = {4},
  eprint = {26753828},
  eprinttype = {pmid},
  pages = {545--571},
  publisher = {{Routledge}},
  issn = {0027-3171},
  doi = {10.1207/s15327906mbr3304_5},
  url = {https://doi.org/10.1207/s15327906mbr3304_5},
  urldate = {2019-12-31},
  abstract = {Analyses of multivariate data are frequently hampered by missing values. Until recently, the only missing-data methods available to most data analysts have been relatively ad1 hoc practices such as listwise deletion. Recent dramatic advances in theoretical and computational statistics, however, have produced anew generation of flexible procedures with a sound statistical basis. These procedures involve multiple imputation (Rubin, 1987), a simulation technique that replaces each missing datum with a set of m {$>$} 1 plausible values. The rn versions of the complete data are analyzed by standard complete-data methods, and the results are combined using simple rules to yield estimates, standard errors, and p-values that formally incorporate missing-data uncertainty. New computational algorithms and software described in a recent book (Schafer, 1997a) allow us to create proper multiple imputations in complex multivariate settings. This article reviews the key ideas of multiple imputation, discusses the software programs currently available, and demonstrates their use on data from the Adolescent Alcohol Prevention Trial (Hansen \& Graham, 199 I).},
  file = {C\:\\Users\\4216318\\Zotero\\storage\\4GAS94IR\\Multiple Imputation for Multivariate Missing Data Problems A Data Analyst s Perspective.pdf;C\:\\Users\\4216318\\Zotero\\storage\\LAV5Z2LK\\Schafer en Olsen - 1998 - Multiple Imputation for Multivariate Missing-Data .pdf;C\:\\Users\\4216318\\Zotero\\storage\\G6SW2LHQ\\s15327906mbr3304_5.html}
}

@article{shiny,
  title = {Shiny: Web Application Framework for {{R}}},
  author = {Chang, Winston and Cheng, Joe and Allaire, JJ and Xie, Yihui and McPherson, Jonathan},
  date = {2017},
  url = {https://CRAN.R-project.org/package=shiny}
}

@article{songWhereMyData2019a,
  title = {Where's {{My Data}}? Evaluating {{Visualizations}} with {{Missing Data}}},
  shorttitle = {Where's {{My Data}}?},
  author = {Song, Hayeong and Szafir, Danielle Albers},
  date = {2019-01},
  journaltitle = {IEEE Transactions on Visualization and Computer Graphics},
  volume = {25},
  number = {1},
  pages = {914--924},
  issn = {1941-0506},
  doi = {10.1109/TVCG.2018.2864914},
  abstract = {Many real-world datasets are incomplete due to factors such as data collection failures or misalignments between fused datasets. Visualizations of incomplete datasets should allow analysts to draw conclusions from their data while effectively reasoning about the quality of the data and resulting conclusions. We conducted a pair of crowdsourced studies to measure how the methods used to impute and visualize missing data may influence analysts' perceptions of data quality and their confidence in their conclusions. Our experiments used different design choices for line graphs and bar charts to estimate averages and trends in incomplete time series datasets. Our results provide preliminary guidance for visualization designers to consider when working with incomplete data in different domains and scenarios.},
  eventtitle = {{{IEEE Transactions}} on {{Visualization}} and {{Computer Graphics}}},
  keywords = {Bars,Data integrity,Data visualization,Data Wrangling,Encoding,Graphical Perception,Imputation,Information Visualization,Interpolation,Time series analysis,Time Series Data,Visualization},
  file = {C\:\\Users\\4216318\\Zotero\\storage\\WS3MTI23\\8440857.html}
}

@article{songWhereMyData2019c,
  title = {Where's {{My Data}}? Evaluating {{Visualizations}} with {{Missing Data}}},
  shorttitle = {Where's {{My Data}}?},
  author = {Song, Hayeong and Szafir, Danielle Albers},
  date = {2019-01},
  journaltitle = {IEEE Transactions on Visualization and Computer Graphics},
  volume = {25},
  number = {1},
  pages = {914--924},
  issn = {1941-0506},
  doi = {10.1109/TVCG.2018.2864914},
  abstract = {Many real-world datasets are incomplete due to factors such as data collection failures or misalignments between fused datasets. Visualizations of incomplete datasets should allow analysts to draw conclusions from their data while effectively reasoning about the quality of the data and resulting conclusions. We conducted a pair of crowdsourced studies to measure how the methods used to impute and visualize missing data may influence analysts' perceptions of data quality and their confidence in their conclusions. Our experiments used different design choices for line graphs and bar charts to estimate averages and trends in incomplete time series datasets. Our results provide preliminary guidance for visualization designers to consider when working with incomplete data in different domains and scenarios.},
  eventtitle = {{{IEEE Transactions}} on {{Visualization}} and {{Computer Graphics}}},
  keywords = {Bars,Data integrity,Data visualization,Data Wrangling,Encoding,Graphical Perception,Imputation,Information Visualization,Interpolation,Time series analysis,Time Series Data,Visualization},
  file = {C\:\\Users\\4216318\\Zotero\\storage\\R6T9UNXC\\8440857.html}
}

@article{su11,
  title = {Multiple {{Imputation}} with {{Diagnostics}} (Mi) in {{R}}: Opening {{Windows}} into the {{Black Box}}},
  shorttitle = {Multiple {{Imputation}} with {{Diagnostics}} (Mi) in {{R}}},
  author = {Su, Yu-Sung and Gelman, Andrew E. and Hill, Jennifer and Yajima, Masanao},
  date = {2011},
  volume = {45},
  number = {2},
  pages = {1--31},
  doi = {10.7916/D8VQ3CD3},
  url = {https://doi.org/10.7916/D8VQ3CD3},
  urldate = {2019-09-10},
  abstract = {Our mi package in R has several features that allow the user to get inside the imputation process and evaluate the reasonableness of the resulting models and imputations. These features include: choice of predictors, models, and transformations for chained imputation models; standard and binned residual plots for checking the fit of the conditional distributions used for imputation; and plots for comparing the distributions of observed and imputed data. In addition, we use Bayesian models and weakly informative prior distributions to construct more stable estimates of imputation models. Our goal is to have a demonstration package that (a) avoids many of the practical problems that arise with existing multivariate imputation programs, and (b) demonstrates state-of-the-art diagnostics that can be applied more generally and can be incorporated into the software of others.},
  langid = {english},
  file = {C\:\\Users\\4216318\\Zotero\\storage\\S5SZMIHW\\Su e.a. - 2011 - Multiple Imputation with Diagnostics (mi) in R Op.pdf;C\:\\Users\\4216318\\Zotero\\storage\\9KLRX5W9\\D8VQ3CD3.html}
}

@inproceedings{twiddyRestorerVisualizationTechnique1994,
  title = {Restorer: A Visualization Technique for Handling Missing Data},
  shorttitle = {Restorer},
  booktitle = {Proceedings {{Visualization}} '94},
  author = {Twiddy, R. and Cavallo, J. and Shiri, S.M.},
  date = {1994-10},
  pages = {212--216},
  doi = {10.1109/VISUAL.1994.346317},
  abstract = {Pseudocoloring is a frequently used technique in scientific visualization for mapping a color to a data value. When using pseudocolor and animation to visualize data that contain missing regions displayed as black or transparent, the missing regions popping in and out can distract the viewer from the more relevant information. Filling these gaps with interpolated data could lead to a misinterpretation of the data. The paper presents a method for combining pseudocoloring and grayscale in the same colormap. Valid data are mapped to colors in the colormap. The luminance values of the colors bounding areas of missing data are used in interpolating over these regions. The missing data are mapped to the grayscale portion of the colormap. This approach has the advantages of eliminating distracting gaps caused by missing data and distinguishing between those areas that represent valid data and those areas that do not. This approach was inspired by a technique used in the restoration of paintings.{$<>$}},
  eventtitle = {Proceedings {{Visualization}} '94},
  keywords = {Art,Brightness,Color,Data visualization,Filling,Gray-scale,Image restoration,Interpolation,NASA,Painting},
  file = {C\:\\Users\\4216318\\Zotero\\storage\\WA2L56EL\\346317.html}
}

@article{vanbuurenMultipleImputationMissing1999,
  ids = {buurenMultipleImputationMissing1999},
  title = {Multiple Imputation of Missing Blood Pressure Covariates in Survival Analysis},
  author = {van Buuren, S. and Boshuizen, H. C. and Knook, D. L.},
  options = {useprefix=true},
  date = {1999-03-30},
  journaltitle = {Statistics in Medicine},
  shortjournal = {Stat Med},
  volume = {18},
  number = {6},
  eprint = {10204197},
  eprinttype = {pmid},
  pages = {681--694},
  issn = {0277-6715},
  doi = {10.1002/(sici)1097-0258(19990330)18:6<681::aid-sim71>3.0.co;2-r},
  abstract = {This paper studies a non-response problem in survival analysis where the occurrence of missing data in the risk factor is related to mortality. In a study to determine the influence of blood pressure on survival in the very old (85+ years), blood pressure measurements are missing in about 12.5 per cent of the sample. The available data suggest that the process that created the missing data depends jointly on survival and the unknown blood pressure, thereby distorting the relation of interest. Multiple imputation is used to impute missing blood pressure and then analyse the data under a variety of non-response models. One special modelling problem is treated in detail; the construction of a predictive model for drawing imputations if the number of variables is large. Risk estimates for these data appear robust to even large departures from the simplest non-response model, and are similar to those derived under deletion of the incomplete records.},
  langid = {english},
  keywords = {Aged,Aged; 80 and over,Blood Pressure,Cohort Studies,Data Collection,Demography,Female,Humans,Male,Meta-Analysis as Topic,Survival Analysis},
  file = {C\:\\Users\\4216318\\Zotero\\storage\\WSSMFDNU\\Multiple imputation - Stat Med 1999.pdf}
}

@article{vanginkelStandardizedRegressionCoefficients2020,
  title = {Standardized {{Regression Coefficients}} and {{Newly Proposed Estimators}} for \$\$\{\vphantom\}{{R}}\vphantom\{\}\^\{\{2\}\}\$\${{R2}} in {{Multiply Imputed Data}}},
  author = {van Ginkel, Joost R.},
  options = {useprefix=true},
  date = {2020-03-11},
  journaltitle = {Psychometrika},
  shortjournal = {Psychometrika},
  issn = {1860-0980},
  doi = {10.1007/s11336-020-09696-4},
  url = {https://doi.org/10.1007/s11336-020-09696-4},
  urldate = {2020-03-23},
  abstract = {Whenever statistical analyses are applied to multiply imputed datasets, specific formulas are needed to combine the results into one overall analysis, also called combination rules. In the context of regression analysis, combination rules for the unstandardized regression coefficients, the t-tests of the regression coefficients, and the F-tests for testing \$\$R\^\{2\}\$\$R2 for significance have long been established. However, there is still no general agreement on how to combine the point estimators of \$\$R\^\{2\}\$\$R2 in multiple regression applied to multiply imputed datasets. Additionally, no combination rules for standardized regression coefficients and their confidence intervals seem to have been developed at all. In the current article, two sets of combination rules for the standardized regression coefficients and their confidence intervals are proposed, and their statistical properties are discussed. Additionally, two improved point estimators of \$\$R\^\{2\}\$\$R2 in multiply imputed data are proposed, which in their computation use the pooled standardized regression coefficients. Simulations show that the proposed pooled standardized coefficients produce only small bias and that their 95\% confidence intervals produce coverage close to the theoretical 95\%. Furthermore, the simulations show that the newly proposed pooled estimates for \$\$R\^\{2\}\$\$R2 are less biased than two earlier proposed pooled estimates.},
  langid = {english},
  file = {C\:\\Users\\4216318\\Zotero\\storage\\Y76EU5BB\\van Ginkel - 2020 - Standardized Regression Coefficients and Newly Pro.pdf}
}

@article{vink14,
  title = {Pooling Multiple Imputations When the Sample Happens to Be the Population},
  author = {Vink, Gerko and van Buuren, Stef},
  options = {useprefix=true},
  date = {2014-09-30},
  url = {http://arxiv.org/abs/1409.8542},
  urldate = {2019-12-13},
  abstract = {Current pooling rules for multiply imputed data assume infinite populations. In some situations this assumption is not feasible as every unit in the population has been observed, potentially leading to over-covered population estimates. We simplify the existing pooling rules for situations where the sampling variance is not of interest. We compare these rules to the conventional pooling rules and demonstrate their use in a situation where there is no sampling variance. Using the standard pooling rules in situations where sampling variance should not be considered, leads to overestimation of the variance of the estimates of interest, especially when the amount of missingness is not very large. As a result, populations estimates are over-covered, which may lead to a loss of statistical power. We conclude that the theory of multiple imputation can be extended to the situation where the sample happens to be the population. The simplified pooling rules can be easily implemented to obtain valid inference in cases where we have observed essentially all units and in simulation studies addressing the missingness mechanism only.},
  keywords = {Mathematics - Statistics Theory,Statistics - Computation},
  file = {C\:\\Users\\4216318\\Zotero\\storage\\9TV8WDM5\\Vink en van Buuren - 2014 - Pooling multiple imputations when the sample happe.pdf;C\:\\Users\\4216318\\Zotero\\storage\\P6KYWI5H\\1409.html}
}

@article{vinkMultipleImputationSquared2013,
  title = {Multiple {{Imputation}} of {{Squared Terms}}},
  author = {Vink, Gerko and van Buuren, Stef},
  options = {useprefix=true},
  date = {2013-11-01},
  journaltitle = {Sociological Methods \& Research},
  shortjournal = {Sociological Methods \& Research},
  volume = {42},
  number = {4},
  pages = {598--607},
  publisher = {{SAGE Publications Inc}},
  issn = {0049-1241},
  doi = {10.1177/0049124113502943},
  url = {https://doi.org/10.1177/0049124113502943},
  urldate = {2020-03-20},
  abstract = {We propose a new multiple imputation technique for imputing squares. Current methods yield either unbiased regression estimates or preserve data relations. No method, however, seems to deliver both, which limits researchers in the implementation of regression analysis in the presence of missing data. Besides, current methods only work under a missing completely at random (MCAR) mechanism. Our method for imputing squares uses a polynomial combination. The proposed method yields both unbiased regression estimates, while preserving the quadratic relations in the data for both missing at random and MCAR mechanisms.},
  langid = {english},
  file = {C\:\\Users\\4216318\\Zotero\\storage\\VBSZWGVA\\Vink en van Buuren - 2013 - Multiple Imputation of Squared Terms.pdf}
}

@article{vinknd,
  title = {Towards a Standardized Evaluation of Multiple Imputation Routines},
  author = {Vink, Gerko},
  year = {\bibstring{nodate}},
  abstract = {Developing new imputation methodology has become a very active field. Unfortunately, there is no consensus on how to perform simulation studies to evaluate the properties of imputation methods. In this paper I propose a move towards a standardized evaluation of imputation methods. To demonstrate the need for standardization, I highlight a set of potential pitfalls that bring forth a chain of potential problems in the objective assessment of the performance of imputation routines. This may lead to suboptimal use of multiple imputation in practice. Additionally, I suggest a course of action for simulating and evaluating missing data problems.},
  langid = {english},
  file = {C\:\\Users\\4216318\\Zotero\\storage\\ZXGCXPP4\\Vink - Towards a standardized evaluation of multiple impu.pdf}
}

@article{whit11,
  ids = {whiteMultipleImputationUsing2011},
  title = {Multiple Imputation Using Chained Equations: Issues and Guidance for Practice},
  shorttitle = {Multiple Imputation Using Chained Equations},
  author = {White, Ian R. and Royston, Patrick and Wood, Angela M.},
  date = {2011-02-20},
  journaltitle = {Statistics in Medicine},
  shortjournal = {Stat Med},
  volume = {30},
  number = {4},
  eprint = {21225900},
  eprinttype = {pmid},
  pages = {377--399},
  issn = {1097-0258},
  doi = {10.1002/sim.4067},
  abstract = {Multiple imputation by chained equations is a flexible and practical approach to handling missing data. We describe the principles of the method and show how to impute categorical and quantitative variables, including skewed variables. We give guidance on how to specify the imputation model and how many imputations are needed. We describe the practical analysis of multiply imputed data, including model building and model checking. We stress the limitations of the method and discuss the possible pitfalls. We illustrate the ideas using a data set in mental health, giving Stata code fragments.},
  langid = {english},
  keywords = {Adolescent,Adult,Aged,Cardiovascular Diseases,Cholesterol,Female,fully conditional specification,Humans,Lipoproteins; HDL,Mental Health,Middle Aged,missing data,Models; Statistical,Multicenter Studies as Topic,multiple imputation,Young Adult},
  file = {C\:\\Users\\4216318\\Zotero\\storage\\FCDQ64HW\\White et al. - 2011 - Multiple imputation using chained equations Issue.pdf;C\:\\Users\\4216318\\Zotero\\storage\\L74SBSX2\\White e.a. - 2011 - Multiple imputation using chained equations Issue.pdf;C\:\\Users\\4216318\\Zotero\\storage\\E69N33FT\\sim.html}
}

@article{zhangSystematicSurveyReporting2017,
  ids = {zhangSystematicSurveyReporting2017a},
  title = {A Systematic Survey on Reporting and Methods for Handling Missing Participant Data for Continuous Outcomes in Randomized Controlled Trials},
  author = {Zhang, Yuqing and Flórez, Ivan D. and Colunga Lozano, Luis E. and Aloweni, Fazila Abu Bakar and Kennedy, Sean Alexander and Li, Aihua and Craigie, Samantha and Zhang, Shiyuan and Agarwal, Arnav and Lopes, Luciane C. and Devji, Tahira and Wiercioch, Wojtek and Riva, John J. and Wang, Mengxiao and Jin, Xuejing and Fei, Yutong and Alexander, Paul and Morgano, Gian Paolo and Zhang, Yuan and Carrasco-Labra, Alonso and Kahale, Lara A. and Akl, Elie A. and Schünemann, Holger J. and Thabane, Lehana and Guyatt, Gordon H.},
  date = {2017-08-01},
  journaltitle = {Journal of Clinical Epidemiology},
  shortjournal = {Journal of Clinical Epidemiology},
  volume = {88},
  pages = {57--66},
  issn = {0895-4356},
  doi = {10.1016/j.jclinepi.2017.05.017},
  url = {http://www.sciencedirect.com/science/article/pii/S0895435617305735},
  urldate = {2020-09-07},
  abstract = {Objective To assess analytic approaches randomized controlled trial (RCT) authors use to address missing participant data (MPD) for patient-important continuous outcomes. Study Design and Setting We conducted a systematic survey of RCTs published in 2014 in the core clinical journals that reported at least one patient-important outcome analyzed as a continuous variable. Results Among 200 studies, 187 (93.5\%) trials explicitly reported whether MPD occurred. In the 163 (81.5\%) trials that reported the occurrence of MPD, the median and interquartile ranges of the percentage of participants with MPD were 11.4\% (2.5\%–22.6\%).Among the 147 trials in which authors made clear their analytical approach to MPD, the approaches chosen included available data only (109, 67\%); mixed-effect models (10, 6.1\%); multiple imputation (9, 4.5\%); and last observation carried forward (9, 4.5). Of the 163 studies reporting MPD, 16 (9.8\%) conducted sensitivity analyses examining the impact of the MPD and (18, 11.1\%) discussed the risk of bias associated with MPD. Conclusion RCTs reporting continuous outcomes typically have over 10\% of participant data missing. Most RCTs failed to use optimal analytic methods, and very few conducted sensitivity analyses addressing the possible impact of MPD or commented on how MPD might influence risk of bias.},
  langid = {english},
  keywords = {Analytic approaches,Continuous outcome,Lost to follow-up,Missing participant data,MPD,Randomized controlled trials},
  file = {C\:\\Users\\4216318\\Zotero\\storage\\WKYT5MN6\\Zhang et al. - 2017 - A systematic survey on reporting and methods for h.pdf;C\:\\Users\\4216318\\Zotero\\storage\\RYYHVQFY\\S0895435617305735.html}
}


